# HE 11 - Economic Evaluation III: Appraising Economic Evaluations Using CHEERS 2022 

**Prepared by: Dr Ainol Haniza Kherul Anuwar**  
**DDS (UGM), MCOH (Distinction) (Malaya), DrDPH (Malaya)**  
**Department of Community Oral Health & Clinical Prevention, Faculty of Dentistry, Universiti Malaya**  
**Credit: Prof Dr Maznah Dahlui, Department of Social & Preventive Medicine, Faculty of Medicine, Universiti Malaya**  
**Lecture Date: June 12, 2025**

---

## üìù Executive Summary

The lecture equips students with the skills to critically appraise economic evaluations using the **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 checklist**, a vital tool for ensuring **transparency**, **clarity**, and **policy usability** in health economics research. Building on foundational concepts from **Economic Evaluation I** and **II**, this session emphasizes the importance of clear reporting to enhance the **credibility** and **policy relevance** of economic evaluations, particularly in resource-constrained settings like Malaysia‚Äôs healthcare system. Through a structured review of the CHEERS framework, practical appraisal techniques, and a case study analysis, students learn to identify reporting gaps, assess study quality, and contribute to **evidence-based health policy** decisions. The lecture underscores that **transparent reporting** is essential for bridging the gap between research and policy, ensuring evaluations are **trustworthy**, **reproducible**, and **actionable** for stakeholders such as Malaysia‚Äôs **MaHTAS** and **Ministry of Health**.

### üéØ Key Learning Outcomes

By the end of the lecture, students are able to:

- **Understand** the purpose and structure of the **CHEERS 2022 checklist**, recognizing its role in ensuring **clarity** and **completeness** in reporting.
- **Identify** the six domains of high-quality economic evaluation reporting, including Title & Abstract, Methods, and Results.
- **Apply** CHEERS to appraise published studies, systematically evaluating reporting quality using a practical coding system (‚úÖ, üü°, ‚ùå).
- **Recognize** common reporting gaps (e.g., missing perspective, incomplete model details) and their implications for **policy relevance**.

### üîç Recap of Foundational Concepts

The lecture begins with a recap of **Economic Evaluation II**, outlining the systematic steps for conducting economic evaluations:

- **Define problem and comparators**, **choose perspective**, **identify, measure, and value costs and outcomes**, **apply discounting**, **calculate the Incremental Cost-Effectiveness Ratio (ICER)**, and **perform sensitivity analysis** and **modeling**.
- **Costing** includes **direct medical** (e.g., hospital stays), **direct non-medical** (e.g., travel), **indirect** (e.g., productivity losses), and **intangible** (e.g., pain) costs, with methods like **micro-costing** and **gross costing**.
- **Outcome measurement** involves **Cost-Effectiveness Analysis (CEA)** (natural units, e.g., life-years), **Cost-Utility Analysis (CUA)** (e.g., **QALYs**, **DALYs**), and **Cost-Benefit Analysis (CBA)** (monetized outcomes).
- **ICER** is calculated as:  
    $$\text{ICER} = \frac{\text{Incremental Cost}}{\text{Incremental QALYs}}$$  
    and compared to thresholds (e.g., willingness-to-pay, GDP per capita).
- **Sensitivity analysis** (one-way, multi-way, probabilistic) tests robustness, while **economic modeling** (e.g., **decision trees**, **Markov models**) simulates long-term or complex outcomes.

**Key Takeaway**: **‚ÄúEven the most precise analysis is only as useful as its clarity; economic evaluation must be methodologically sound and transparently reported.‚Äù**

### ‚ùì Importance of Critical Appraisal

Critical appraisal ensures that economic evaluations are **credible** and **policy-relevant**:

- **Problem**: Many studies appear robust with **advanced modeling** and **impressive ICERs** but lack credibility due to **poor reporting**.
- **Consequences of Poor Reporting**:
    - Cannot be **replicated** or **adapted** to contexts like Malaysia.
    - May **mislead policy decisions**, leading to **low trust** and **limited impact**.
- **Benefits of Well-Reported Studies**:
    - Support **justifiable reimbursement** (e.g., Peka B40), **efficient resource allocation** (e.g., cancer screening vs. ICU beds), and **HTA inclusion** (e.g., MaHTAS reviews).
- **Key Message**: **‚ÄúA strong economic evaluation is not just about having the right model, it‚Äôs about reporting it clearly, so others can evaluate and trust your results.‚Äù**

### üìã Understanding CHEERS 2022

The **CHEERS 2022 checklist**, developed by **ISPOR**, standardizes reporting to enhance **clarity** and **completeness**:

- **First Released**: 2013, updated in 2022.
- **Purpose**: Improve reporting, not judge study quality.
- **What It Is/Isn‚Äôt**:
    
|**CHEERS IS**|**CHEERS IS NOT**|
|---|---|
|A reporting checklist|A quality scoring tool|
|A guide for authors, reviewers, policy users|A tool for determining ‚Äúgood‚Äù vs. ‚Äúbad‚Äù studies|
|Applicable to all economic evaluations|A substitute for peer review|
    
- **Why It Matters**: Addresses **incomplete or inconsistent reporting**, meeting stakeholder needs for **transparent methods**, **clear assumptions**, and **reproducible results**.
- **Example**: A study claiming ‚ÄúQALYs were estimated‚Äù without specifying the utility tool, preferences, or time horizon renders the ICER **uninterpretable**.
- **Policy Use**: Adopted by **HTA agencies** (e.g., NICE, MaHTAS), **journals**, and **researchers** to support **evidence transparency**.

**Key Takeaway**: **‚ÄúIf it‚Äôs not reported, it didn‚Äôt happen. CHEERS ensures every essential part of an economic evaluation is visible, understandable, and usable.‚Äù**

### üß© CHEERS 2022 Structure

The CHEERS 2022 checklist includes **28 items** across **6 domains**:

|**Domain**|**Purpose**|**Key Examples**|
|---|---|---|
|Title & Abstract|Identify as economic evaluation, summarize findings|Label study type, summarize ICER|
|Introduction|Explain research question and policy relevance|State objective, context|
|Methods|Describe how evaluation was conducted|Perspective, time horizon, modeling|
|Results|Present outcomes clearly|ICER, uncertainty, subgroups|
|Discussion|Reflect on limitations and implications|Generalizability, equity|
|Other Information|Promote transparency, reproducibility|Funding, conflicts of interest|

**Key Message**: **‚ÄúEach domain tells part of the story. CHEERS doesn‚Äôt ask if your results are correct, only if readers can understand what you did, why, and how.‚Äù**

### üî¨ Focus on the Methods Section

The **methods section** is the **engine room** of an economic evaluation, covering **18 CHEERS items** (4‚Äì21) like perspective, costing, and modeling:

- **Why Critical**: Determines if findings are **understandable**, **reproducible**, and **policy-relevant**.
- **Example Gaps**:
    
|**CHEERS Item**|**Strong Reporting**|**Weak Reporting**|
|---|---|---|
|Perspective|‚ÄúHealth system perspective, per MaHTAS guidelines‚Äù|‚ÄúCosts were included‚Äù|
|Discount Rate|‚Äú3% annually, per HTA norms‚Äù|‚ÄúDiscounting applied‚Äù|
|Sensitivity Analysis|‚ÄúOne-way and probabilistic analyses on costs, utilities‚Äù|‚ÄúSensitivity analysis done‚Äù|
    
- **Critical Question**: **‚ÄúCould a policymaker or researcher reproduce this study based on the methods reported?‚Äù**

### üõ†Ô∏è Applying CHEERS in Practice

Applying CHEERS involves:

1. **Read section by section** (Title/Abstract ‚Üí Discussion).
2. **Match sections to CHEERS items**.
3. **Evaluate** using a coding system:
    
|**Symbol**|**Meaning**|
|---|---|
|‚úÖ|Clearly reported|
|üü°|Unclear/incomplete|
|‚ùå|Not reported|
    

This systematic approach ensures **transparent** and **objective** appraisal, critical for policy contexts like Malaysia.

### üìñ Case Study: Appraising a Published Study

The lecture appraises a study by Hofer et al. (2018) on lung cancer screening:

- **Title**: _Cost-utility analysis of a potential lung cancer screening program for a high-risk population in Germany: A modelling approach_
- **Objective**: Evaluate cost-effectiveness from a **public payer perspective** for heavy smokers (aged 55‚Äì75).
- **Methods**: Two **Markov models**, 60 cycles (3-month length), outcomes (costs, life years, QALYs), deterministic/probabilistic sensitivity analyses.
- **Results**: Incremental costs (‚Ç¨1,153/person), gains (0.06 life years, 0.04 QALYs), ICER (‚Ç¨19,302/LY, ‚Ç¨30,291/QALY).
- **Appraisal**: 17 items ‚úÖ (e.g., perspective, results), 4 üü° (e.g., QALY valuation), 7 ‚ùå (e.g., subgroup heterogeneity, stakeholder engagement).

The appraisal highlights **strong reporting** in most areas but gaps in equity and stakeholder engagement, limiting full **policy applicability**.

### üö® Common Reporting Gaps

The **top five reporting gaps** include:

1. **Perspective Not Stated**: Misleads on cost/outcome scope (e.g., drug costs claimed as societal).
2. **No Justification for Time Horizon/Discount Rate**: Undermines long-term credibility (e.g., lifetime model without discounting).
3. **Omission of Sensitivity Analysis**: Limits uncertainty assessment (e.g., ICER without robustness testing).
4. **Incomplete Model Structure**: Hinders replication (e.g., Markov model without state details).
5. **Utility Sources Not Reported**: Affects QALY reliability (e.g., ‚Äúliterature weights‚Äù without citation).

These gaps reduce **trust**, **reproducibility**, and **policy uptake**, emphasizing the need for CHEERS compliance.

### üåç Policy Impact of Transparent Reporting

**Transparent reporting** enhances policy impact by:

- Supporting **HTAs**, **budget allocation**, **reimbursement** (e.g., Peka B40), and **guidelines**.
- **Local Relevance**: MaHTAS, HITAP, and NICE require CHEERS compliance for **MyHTA reports**, **pharmacoeconomic documents**, and **regional dialogues**.
- **Key Insight**: **‚ÄúHealth systems don‚Äôt make million-ringgit decisions on vague data. CHEERS bridges the gap between research and policy.‚Äù**

### üóùÔ∏è Final Takeaways

- **CHEERS 2022** enhances **clarity**, **transparency**, and **policy usability**.
- **Appraisal** assesses **communication clarity**, complementing peer review.
- **Gaps** (e.g., missing perspective) reduce trust and applicability.
- **Transparent reporting** builds **trust** and **policy uptake**, critical for Malaysia‚Äôs healthcare system.

### üìö Key Terminologies Introduced

The lecture introduces critical terms essential for understanding and appraising economic evaluations:

- **CHEERS (Consolidated Health Economic Evaluation Reporting Standards)**: A checklist to ensure transparent and complete reporting of economic evaluations, updated in 2022 by ISPOR.
- **Economic Evaluation**: A comparative analysis of interventions‚Äô costs and outcomes, guiding resource allocation (e.g., CEA, CUA, CBA).
- **Incremental Cost-Effectiveness Ratio (ICER)**:  
    $$\text{ICER} = \frac{\text{Incremental Cost}}{\text{Incremental QALYs}}$$  
    Measures additional cost per health outcome gained, compared to thresholds like GDP per capita.
- **Quality-Adjusted Life Year (QALY)**: A utility-based outcome combining life expectancy and quality of life, often measured using tools like **EQ-5D**.
- **Disability-Adjusted Life Year (DALY)**: A measure of disease burden, reflecting years lost due to disability or premature death.
- **Perspective**: The viewpoint (e.g., societal, health system, payer) determining which costs and outcomes are included.
- **Sensitivity Analysis**: Tests result robustness by varying parameters (one-way, multi-way, probabilistic).
- **Economic Modeling**: Simulates long-term or complex outcomes using models like **decision trees** or **Markov models**.
- **Health Technology Assessment (HTA)**: Evaluates interventions‚Äô cost-effectiveness for adoption, used by agencies like **MaHTAS**.
- **Micro-costing**/**Gross costing**: Detailed (unit-level) vs. aggregated cost estimation methods.
- **Peka B40**: Malaysia‚Äôs healthcare program for low-income groups, informed by economic evaluations.
- **MaHTAS**: Malaysia Health Technology Assessment Section, requiring CHEERS-compliant reporting.

---

## üìö 1. Introduction to the Lecture

This lecture focuses on the critical appraisal of economic evaluations using the **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 checklist**. Economic evaluations are essential tools for informing health policy, but their value depends on clear and transparent reporting. Poorly reported studies, even if methodologically sound, can lack credibility and fail to influence policy decisions. This session equips students with the skills to evaluate the **transparency** and **clarity** of economic evaluation studies, ensuring their findings are robust, reproducible, and applicable to **public health policy decisions** in contexts like Malaysia‚Äôs health system.

The lecture builds on concepts from **Economic Evaluation I** and **II**, where students learned the foundations of economic evaluation, including costing, outcome measurement, and the Incremental Cost-Effectiveness Ratio (ICER). Here, the focus shifts to assessing how well studies communicate their methods and results, using the CHEERS 2022 checklist as a structured framework. By mastering this appraisal process, students will be able to identify high-quality studies, recognize reporting gaps, and contribute to **evidence-based policymaking** that maximizes health outcomes within resource constraints.

### üéØ Learning Outcomes

By the end of this session, students will be able to:

- **Understand the purpose and structure of the CHEERS 2022 checklist**: Grasp how CHEERS ensures **clarity** and **completeness** in reporting, enabling stakeholders to trust and use economic evaluations effectively.
- **Identify the key domains of high-quality economic evaluation reporting**: Recognize the six domains of CHEERS (Title & Abstract, Introduction, Methods, Results, Discussion, and Other Information) and their role in transparent reporting.
- **Apply CHEERS to appraise published economic evaluation studies**: Use the checklist to systematically evaluate studies, assessing whether they meet reporting standards and are suitable for informing policy.
- **Recognise common reporting gaps and their implications**: Identify frequent deficiencies, such as missing perspectives or incomplete model descriptions, and understand how these undermine the **credibility** and **policy relevance** of studies.

These outcomes empower students to critically evaluate economic evaluations, ensuring they can contribute to **transparent**, **efficient**, and **equitable** health resource allocation as public health professionals, researchers, or policymakers.

---

## üîç 2. Recap of Economic Evaluation II

This section provides a comprehensive review of the foundational concepts covered in **Economic Evaluation II**, setting the stage for understanding the critical appraisal process in **Economic Evaluation III**. It outlines the systematic steps for conducting a full economic evaluation, details the types and methods of costing, explains outcome measurement approaches, introduces the Incremental Cost-Effectiveness Ratio (ICER), and explores sensitivity analysis and economic modeling. These concepts are crucial for assessing the **transparency** and **clarity** of economic evaluations using the **CHEERS 2022 checklist**, as they form the methodological backbone that must be clearly reported for policy relevance. The recap emphasizes the importance of **methodological rigor** and **transparent reporting** to ensure evaluations are robust and usable in health policy decisions, such as those by Malaysia‚Äôs **MaHTAS** or other Health Technology Assessment (HTA) bodies.

### Steps in Conducting a Full Economic Evaluation

A **systematic approach** is essential for conducting robust and policy-relevant economic evaluations. These evaluations provide a structured framework to compare health interventions, ensuring that limited resources are allocated efficiently to maximize health outcomes. The key steps are:

- **Define the problem and comparators**: Clearly articulate the health issue and identify the interventions to be compared (e.g., a new drug vs. standard care). This step ensures the evaluation addresses a specific, relevant question.
- **Choose the perspective**: Select the viewpoint (e.g., **societal**, **health system**) that determines which costs and outcomes are included. For example, a societal perspective includes all costs, while a health system perspective focuses on direct medical costs.
- **Identify, measure, and value costs and outcomes**: Systematically account for all relevant costs (e.g., medical, non-medical) and outcomes (e.g., life-years, QALYs), quantifying them accurately to enable fair comparisons.
- **Apply discounting and set a relevant time horizon**: Adjust future costs and outcomes using a discount rate (e.g., 3%) to reflect their present value, and choose an appropriate time frame (e.g., lifetime for chronic diseases) to capture all relevant effects.
- **Calculate and interpret the Incremental Cost-Effectiveness Ratio (ICER)**: Compute the ICER to compare the additional costs and benefits of one intervention over another, interpreting it against thresholds like willingness-to-pay or GDP per capita.
- **Perform sensitivity analysis and, when needed, economic modeling**: Test the robustness of results by varying key parameters and use models (e.g., Markov models) to simulate long-term or complex outcomes.

These steps ensure that economic evaluations are **comprehensive**, **transparent**, and **aligned** with policy needs, providing decision-makers with reliable evidence to prioritize interventions.

### Costing in Economic Evaluations

Costing is a critical component of economic evaluations, as it quantifies the resources consumed by an intervention. Accurate costing ensures that evaluations reflect the true economic burden and enable fair comparisons between alternatives.

- **Types of Costs**:
    - **Direct Medical**: Costs directly related to healthcare delivery, such as **hospital stays** (e.g., ward costs, surgical procedures) and **medications** (e.g., drug prescriptions).
    - **Direct Non-Medical**: Costs incurred outside healthcare but related to accessing it, such as **travel** (e.g., transportation to clinics) and **caregiving** (e.g., time spent by family members).
    - **Indirect**: Economic impacts beyond direct expenses, such as **productivity losses** (e.g., lost wages due to illness or treatment).
    - **Intangible**: Non-financial costs that are difficult to quantify, such as **pain** or **suffering** experienced by patients, often considered qualitatively.
- **Costing Methods**:
    - **Micro-costing**: A detailed approach that identifies and measures each resource unit (e.g., cost per hospital bed-day, per consultation), providing high precision but requiring extensive data.
    - **Gross costing**: An aggregated approach that uses average or total costs (e.g., cost per patient episode), which is simpler but less detailed.
- **Perspective**: The chosen perspective determines which costs are included. For example:
    - A **societal perspective** includes all costs (medical, non-medical, indirect, and sometimes intangible).
    - A **health system perspective** focuses solely on direct medical costs, relevant for bodies like Malaysia‚Äôs **Ministry of Health (MOH)**.

Proper costing ensures that evaluations capture the full economic impact of interventions, aligning with the decision-maker‚Äôs perspective and context.

### Outcome Measurement

Measuring outcomes is essential for assessing the **health benefits** of interventions. Different types of economic evaluations use distinct outcome measures, each suited to specific decision-making needs.

- **Cost-Effectiveness Analysis (CEA)**: Measures outcomes in **natural units**, such as:
    - **Life-years gained**: Extending survival through treatments like heart surgery.
    - **Cases prevented**: Reducing disease incidence through interventions like vaccinations.
- **Cost-Utility Analysis (CUA)**: Uses **utility-based measures** that account for both quantity and quality of life, such as:
    - **Quality-Adjusted Life Years (QALYs)**: Combines life expectancy with quality of life, where 1 QALY represents one year in perfect health.
    - **Disability-Adjusted Life Years (DALYs)**: Quantifies disease burden by measuring years lost due to disability or premature death.
- **Cost-Benefit Analysis (CBA)**: **Monetizes outcomes**, converting health benefits into monetary values (e.g., the financial value of productivity gains from a health program).
- **Utility Values**: Essential for QALY calculations, these are often derived from standardized tools like **EQ-5D**, which measures health-related quality of life across dimensions like mobility and pain. These values reflect patient or population preferences, ensuring outcomes are meaningful.

Selecting the appropriate outcome measure ensures that evaluations capture the most relevant health impacts, facilitating comparisons across interventions.

### ICER and Thresholds

The **Incremental Cost-Effectiveness Ratio (ICER)** is a key metric in economic evaluations, quantifying the additional cost per unit of additional health benefit when comparing two interventions.

- **Calculation**:  
    $$\text{ICER} = \frac{\text{Incremental Cost}}{\text{Incremental QALYs}}$$
    
    - **Incremental Cost**: The difference in costs between the intervention and its comparator (e.g., new treatment vs. standard care).
    - **Incremental QALYs**: The difference in QALYs gained between the two options.
    - **Example**: If a new drug costs an additional RM50,000 and provides 0.5 extra QALYs compared to standard care, the ICER is:  
        $$\text{ICER} = \frac{50000}{0.5} = 100000 , \text{RM per QALY}$$
- **Interpretation**: The ICER is compared to **thresholds** to determine cost-effectiveness:
    
    - **Willingness-to-pay (WTP)**: The maximum amount a decision-maker is willing to pay for an additional unit of outcome (e.g., RM100,000 per QALY).
    - **GDP per capita**: Often used as a benchmark (e.g., 1‚Äì3 times GDP per capita in Malaysia for cost-effectiveness).
    - If the ICER is below the threshold, the intervention is considered cost-effective.
- **Influences**: The ICER is sensitive to:
    
    - **Time horizon**: A longer horizon (e.g., lifetime) may capture more benefits, lowering the ICER.
    - **Discounting**: Applying a discount rate (e.g., 3%) reduces the value of future costs and outcomes, affecting the ICER.

The ICER provides a standardized measure to guide resource allocation decisions, ensuring that interventions deliver value for money.

### Sensitivity Analysis

**Sensitivity analysis** tests the **robustness** of economic evaluation results by examining how changes in key parameters affect conclusions. It is critical for addressing uncertainty and ensuring that findings are reliable for policy decisions.

- **Types**:
    - **One-way**: Varies one parameter at a time (e.g., drug cost) to assess its impact on the ICER, identifying key drivers of results.
    - **Multi-way**: Varies multiple parameters simultaneously to explore combined effects, providing a broader view of uncertainty.
    - **Probabilistic**: Uses probability distributions for parameters (e.g., costs, utilities) to simulate a range of outcomes, often presented as cost-effectiveness acceptability curves.
- **Purpose**:
    - **Tests robustness**: Determines whether conclusions hold under different assumptions or data inputs.
    - **Identifies uncertainty**: Highlights parameters with the greatest impact on results, guiding further research or data collection.
    - **Example**: In a cancer treatment evaluation, sensitivity analysis might show that the ICER is highly sensitive to drug cost but robust to changes in utility values.

Sensitivity analysis ensures that evaluations are **transparent** about uncertainty, enabling policymakers to make informed decisions with confidence.

### Economic Modelling

**Economic modeling** is used when direct data are insufficient to capture long-term or complex outcomes, allowing analysts to simulate the impacts of interventions over time or across scenarios.

- **When Used**: Models are necessary for:
    - **Long-term outcomes**: When benefits (e.g., survival gains) extend beyond trial data (e.g., 10-year impacts of a cancer drug).
    - **Complex pathways**: When interventions involve multiple health states or transitions (e.g., chronic diseases with remission and relapse).
- **Types**:
    - **Decision Trees**: Suitable for **short-term outcomes**, modeling discrete choices and outcomes (e.g., surgical vs. non-surgical treatment for appendicitis).
    - **Markov Models**: Ideal for **chronic or recurrent conditions**, simulating transitions between health states over time (e.g., cancer progression with remission, relapse, and death states).
- **Example**: A Markov model for a diabetes intervention might simulate transitions between ‚Äúhealthy,‚Äù ‚Äúcomplications,‚Äù and ‚Äúdeath‚Äù states to estimate long-term costs and QALYs.

Economic modeling enhances the flexibility and applicability of evaluations, enabling decision-makers to assess interventions in scenarios where empirical data are limited.

### üóùÔ∏è Key Takeaway

> **‚ÄúEven the most precise analysis is only as useful as its clarity; economic evaluation must be methodologically sound and transparently reported.‚Äù**

This underscores the dual importance of **methodological rigor** and **transparent reporting**. A technically accurate evaluation is ineffective if its methods, assumptions, and results are not clearly communicated to stakeholders like policymakers or HTA agencies (e.g., MaHTAS). Transparent reporting ensures that evaluations are **reproducible**, **trustworthy**, and **usable** for informing health policy decisions, bridging the gap between research and real-world impact.

---

## ‚ùì 3. Why Critical Appraisal Matters

This section explores the critical importance of appraising economic evaluations to ensure their **credibility** and **utility** in health policy decision-making. While many economic evaluations appear robust, with sophisticated statistical methods and impressive results, their value hinges on **transparent reporting**. Without clear and complete reporting, even the most methodologically sound studies can lack credibility, limiting their impact on public health policy. Critical appraisal, guided by tools like the **CHEERS 2022 checklist**, enables stakeholders to assess whether evaluations are **reproducible**, **adaptable**, and **trustworthy**, particularly in contexts like Malaysia‚Äôs health system. By understanding the consequences of poor reporting and the benefits of well-reported studies, students will appreciate the role of critical appraisal in supporting **evidence-based**, **efficient**, and **equitable** resource allocation.

### The Problem with Economic Evaluations

Many economic evaluations appear robust but lack credibility due to poor reporting, undermining their ability to inform policy decisions effectively.

- **Look statistically rigorous** and use **advanced modeling**: Evaluations often employ complex statistical techniques or sophisticated models, such as Markov models, to simulate long-term outcomes, giving the impression of high quality.
- **Show impressive ICERs**: Results, such as low Incremental Cost-Effectiveness Ratios (ICERs), may suggest cost-effectiveness, making the intervention appear highly valuable.
- **Problem**: **If key details aren‚Äôt reported, we can‚Äôt assess their credibility.** Without clear documentation of methods, assumptions, or data sources, stakeholders cannot verify the validity of the results, rendering even the most precise analysis unreliable.

This issue highlights the need for critical appraisal to scrutinize the **transparency** and **completeness** of economic evaluations, ensuring they meet the standards required for policy relevance.

### Consequences of Poor Reporting

Poorly reported evaluations have significant drawbacks that limit their utility and impact in health policy and practice.

- **Cannot be replicated**: Without detailed reporting of methods (e.g., data sources, model structure), other researchers or policymakers cannot reproduce the study to confirm its findings.
- **Cannot be adapted to other contexts (e.g., Malaysia)**: Incomplete reporting prevents the application of results to different settings, such as adapting a study conducted in a high-income country to Malaysia‚Äôs resource-constrained health system.
- **May mislead policy decisions**: Vague or incomplete information can lead to incorrect conclusions, potentially resulting in inefficient or inequitable resource allocation.
- **Lack transparency**, leading to **low trust** and **limited impact**: Stakeholders, such as Malaysia‚Äôs **Ministry of Health** or **MaHTAS**, are less likely to trust or act on studies that lack clear reporting, reducing their influence on policy.

These consequences underscore the critical need for transparent reporting to ensure evaluations are **trustworthy** and **actionable** for decision-makers.

### Importance for Public Health and Policy

Well-reported studies, appraised using tools like CHEERS 2022, enable robust and informed decision-making in public health, supporting efficient and equitable resource allocation.

- **Justifiable reimbursement decisions**: Clear reporting allows policymakers to make evidence-based decisions about funding interventions, such as including treatments in Malaysia‚Äôs **Peka B40** program, which provides healthcare support for low-income groups.
- **Efficient resource allocation**: Transparent evaluations help prioritize interventions that maximize health outcomes within budget constraints, such as deciding whether to invest in **cancer screening** programs or additional **ICU beds**.
- **Inclusion in Health Technology Assessments (HTAs)**: Well-reported studies are more likely to meet the rigorous standards of HTA bodies like **MaHTAS** (Malaysia Health Technology Assessment Section), ensuring they inform national health policies and guidelines.

By providing **clarity** and **transparency**, well-reported evaluations strengthen the evidence base for health policy, enhancing trust and uptake among decision-makers.

### üóùÔ∏è Key Message

> **‚ÄúA strong economic evaluation is not just about having the right model, it‚Äôs about reporting it clearly, so others can evaluate and trust your results.‚Äù**

This emphasizes that the value of an economic evaluation lies not only in its methodological rigor but also in its ability to communicate findings clearly. Transparent reporting ensures that stakeholders, such as policymakers, researchers, and HTA agencies, can **evaluate**, **trust**, and **apply** the results to make informed decisions that optimize health outcomes within limited resources.

---

## üìã 4. Understanding CHEERS 2022

The **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022** is a critical framework for ensuring **clarity** and **completeness** in the reporting of economic evaluations. Developed by the **International Society for Pharmacoeconomics and Outcomes Research (ISPOR)**, CHEERS 2022 provides a standardized checklist to enhance the **transparency** and **usability** of economic evaluations, making them accessible to decision-makers, researchers, and health technology assessment (HTA) agencies. By understanding what CHEERS is, its purpose, and its role in policy and research, students will gain the tools to critically appraise studies, ensuring they meet the rigorous reporting standards needed to inform **evidence-based health policy** decisions in contexts like Malaysia‚Äôs healthcare system. This section sets the foundation for applying CHEERS to evaluate the quality of reporting in published studies, a key skill for public health professionals.

### What is CHEERS?

**CHEERS** (Consolidated Health Economic Evaluation Reporting Standards) is a reporting framework developed by the **International Society for Pharmacoeconomics and Outcomes Research (ISPOR)** to standardize and improve the reporting of economic evaluations in healthcare.

- **First Released**: 2013, establishing an initial set of guidelines to promote consistent reporting.
- **Updated**: 2022, incorporating advancements in health economics and feedback from stakeholders to enhance clarity and applicability.
- **Purpose**: Improve **reporting clarity and completeness**, not to judge study quality. CHEERS ensures that all essential components of an economic evaluation are clearly documented, enabling stakeholders to understand and trust the findings without assessing their methodological validity.

CHEERS serves as a vital tool for authors, reviewers, and policymakers, ensuring that economic evaluations are **transparent**, **reproducible**, and **policy-relevant**, particularly for HTA bodies like Malaysia‚Äôs **MaHTAS**.

### CHEERS: What It Is and Isn‚Äôt

To clarify its role, CHEERS is distinguished by what it is designed to achieve and what it does not do. The following table summarizes its scope:

|**CHEERS IS**|**CHEERS IS NOT**|
|---|---|
|A reporting checklist|A quality scoring tool|
|A guide for authors, reviewers, and policy users|A tool for determining ‚Äúgood‚Äù vs. ‚Äúbad‚Äù studies|
|Applicable to all types of economic evaluation|A substitute for technical peer review|

- **A reporting checklist**: CHEERS provides a structured list of items to ensure all critical aspects of an economic evaluation (e.g., methods, results, assumptions) are reported clearly.
- **A guide for authors, reviewers, and policy users**: It assists researchers in preparing manuscripts, reviewers in evaluating submissions, and policymakers in interpreting findings for decision-making.
- **Applicable to all types of economic evaluation**: CHEERS is versatile, covering cost-effectiveness analysis (CEA), cost-utility analysis (CUA), cost-benefit analysis (CBA), and cost-minimization analysis (CMA).
- **Not a quality scoring tool**: CHEERS focuses on reporting transparency, not on assessing the methodological rigor or validity of the study‚Äôs results.
- **Not a tool for determining ‚Äúgood‚Äù vs. ‚Äúbad‚Äù studies**: It evaluates whether a study is clearly reported, not whether its conclusions are correct.
- **Not a substitute for technical peer review**: CHEERS complements, but does not replace, detailed methodological scrutiny by experts.

> **‚ÄúCHEERS tells you if the study was clearly and completely reported‚Äînot whether the results are valid.‚Äù**

This distinction ensures that CHEERS is used appropriately as a **reporting standard**, guiding stakeholders to focus on transparency rather than substituting for in-depth technical evaluation.

### Why CHEERS Matters

The importance of CHEERS lies in addressing the pervasive issue of **incomplete or inconsistent reporting** in economic evaluations, which undermines their utility for decision-making.

- **Issue**: Reporting in economic evaluations is often **incomplete or inconsistent**, making it difficult for stakeholders to understand or trust the findings.
- **Needs of Stakeholders**:
    - **Decision-makers**, **HTA agencies** (e.g., **NICE** in the UK, **MaHTAS** in Malaysia), and **journals** require:
        - **Transparent methods**: Clear documentation of how the study was conducted, including data sources and analytical approaches.
        - **Clear assumptions**: Explicit reporting of assumptions (e.g., discount rates, utility values) to enable scrutiny.
        - **Reproducible results**: Sufficient detail to allow other researchers or policymakers to replicate or adapt the study.
- **Example**: A study claims ‚ÄúQALYs were estimated‚Äù but omits critical details:
    - Which **utility tool** was used (e.g., EQ-5D, SF-6D)?
    - **Whose preferences** were considered (e.g., patient or population-based)?
    - **Time horizon** or **discounting details** (e.g., 3% discount rate, lifetime horizon)?
    - **Impact**: Without these details, even a correct Incremental Cost-Effectiveness Ratio (ICER) is **uninterpretable**, as stakeholders cannot assess its validity or relevance.

Incomplete reporting reduces the credibility of evaluations, limiting their ability to inform **evidence-based decisions** in health policy and practice.

### CHEERS in Policy and Research

CHEERS 2022 is widely adopted across various domains, reinforcing its role in promoting **evidence transparency** in health system decision-making.

- **Used By**:
    - **HTA Agencies**: Organizations like **NICE** (National Institute for Health and Care Excellence, UK) and **MaHTAS** (Malaysia Health Technology Assessment Section) rely on CHEERS-compliant reporting to evaluate interventions for inclusion in health systems or national guidelines.
    - **Peer-Reviewed Journals**: Leading journals require CHEERS compliance to ensure published studies are transparent and reproducible, enhancing their scientific integrity.
    - **Researchers** preparing manuscripts: CHEERS guides researchers in structuring their reports to meet the expectations of journals and policymakers.
- **Alignment**: CHEERS supports the growing emphasis on **evidence transparency** in health system decision-making, ensuring that economic evaluations are accessible, understandable, and actionable for stakeholders like Malaysia‚Äôs **Ministry of Health**.

By standardizing reporting, CHEERS bridges the gap between research and policy, enabling evaluations to inform critical decisions such as **reimbursement**, **resource allocation**, and **national health priorities**.

### üóùÔ∏è Key Takeaway

> **‚ÄúIf it‚Äôs not reported, it didn‚Äôt happen. CHEERS ensures every essential part of an economic evaluation is visible, understandable, and usable.‚Äù**

This underscores the critical role of CHEERS in making economic evaluations **visible**, **understandable**, and **usable** for stakeholders. By ensuring that every essential component‚Äîsuch as methods, assumptions, and results‚Äîis clearly reported, CHEERS enhances the **trustworthiness** and **policy relevance** of evaluations, enabling informed decision-making in resource-constrained settings like Malaysia‚Äôs healthcare system.

---

## üß© 5. CHEERS 2022 Structure

This section outlines the **structure** of the **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 checklist**, a comprehensive framework designed to ensure **transparency** and **completeness** in reporting economic evaluations. The CHEERS 2022 checklist comprises **28 reporting items** grouped into **6 domains**, each addressing a specific aspect of an economic evaluation to make it clear, understandable, and usable for stakeholders such as policymakers, researchers, and Health Technology Assessment (HTA) agencies like Malaysia‚Äôs **MaHTAS**. By detailing the domains and listing all 28 items, this section equips students with a thorough understanding of how CHEERS organizes reporting requirements to enhance the **credibility** and **policy relevance** of economic evaluations. This knowledge is essential for critically appraising studies and ensuring they meet the standards needed to inform **evidence-based health policy** decisions.

### Overview of CHEERS 2022 Domains

The **CHEERS 2022 checklist** comprises **28 reporting items** grouped into **6 domains**, each ensuring transparency in a specific aspect of economic evaluation reporting. These domains collectively ensure that every critical component of an economic evaluation‚Äîfrom its purpose to its funding sources‚Äîis clearly documented, enabling stakeholders to assess and apply the findings effectively.

The following table summarizes the **6 domains**, their **purpose**, and **key examples** of reporting requirements:

|**Domain**|**Purpose**|**Key Examples**|
|---|---|---|
|**Title & Abstract**|Ensure readers know this is an economic evaluation and can grasp the findings|Clearly label study type; summarize ICER|
|**Introduction**|Explain the research question and its policy relevance|State objective, context, decision need|
|**Methods**|Describe how the evaluation was conducted|Perspective, time horizon, model structure, costing, discounting, sensitivity analysis|
|**Results**|Present the key outcomes clearly|ICER, base case results, uncertainty, subgroups|
|**Discussion**|Reflect on limitations and implications|Generalizability, equity, ethical considerations|
|**Other Information**|Promote transparency and reproducibility|Funding source, conflict of interest, data/model access|

- **Title & Abstract**: Ensures the study is immediately identifiable as an economic evaluation and provides a concise summary of key findings, such as the Incremental Cost-Effectiveness Ratio (ICER), to guide readers.
- **Introduction**: Clarifies the study‚Äôs purpose and its relevance to policy or practice, setting the context for decision-making (e.g., addressing a specific health issue in Malaysia).
- **Methods**: Details the technical aspects of the evaluation, including perspective, time horizon, and analytical approaches, to ensure reproducibility and transparency.
- **Results**: Presents outcomes clearly, including ICERs and uncertainty analyses, to enable stakeholders to understand the evaluation‚Äôs findings.
- **Discussion**: Reflects on the study‚Äôs limitations, generalizability, and broader implications, such as equity or ethical considerations, to contextualize its impact.
- **Other Information**: Enhances transparency by reporting funding sources, conflicts of interest, and data accessibility, ensuring accountability.

This structured approach ensures that each domain contributes to a **complete narrative** of the economic evaluation, making it accessible and actionable for stakeholders.

### Complete List of CHEERS 2022 Items

The CHEERS 2022 checklist includes **28 reporting items**, each addressing a specific element of an economic evaluation to ensure **clarity**, **completeness**, and **transparency**:

1. **Title**: Identify the study as an economic evaluation and specify the interventions being compared, ensuring readers immediately recognize the study‚Äôs focus and scope.
2. **Abstract**: Provide a structured summary that highlights context, key methods, results, and alternative analyses, offering a concise overview for quick reference.
3. **Background & Objectives**: Give the context for the study, the study question, and its practical relevance for decision-making in policy or practice, clarifying why the evaluation was conducted.
4. **Health Economic Analysis Plan**: Indicate whether a health economic analysis plan was developed and where it is available, promoting transparency in study design.
5. **Study Population**: Describe characteristics of the study population (e.g., age range, demographics, socioeconomic, or clinical characteristics), ensuring the target group is clearly defined.
6. **Setting & Location**: Provide relevant contextual information that may influence findings, such as geographic or healthcare system details, to aid interpretation.
7. **Comparators**: Describe the interventions or strategies being compared and why they were chosen, justifying the selection of alternatives.
8. **Perspective**: State the perspective(s) adopted by the study (e.g., societal, health system) and why chosen, clarifying which costs and outcomes are included.
9. **Time Horizon**: State the time horizon for the study (e.g., lifetime, 5 years) and why it is appropriate, ensuring alignment with the intervention‚Äôs expected impact.
10. **Discount Rate**: Report the discount rate(s) (e.g., 3%) and reason chosen, explaining how future costs and outcomes are adjusted.
11. **Selection of Outcomes**: Describe what outcomes were used as the measure(s) of benefit(s) and harm(s), such as QALYs or life-years gained.
12. **Measurement of Outcomes**: Describe how outcomes used to capture benefit(s) and harm(s) were measured, detailing tools like EQ-5D for QALYs.
13. **Valuation of Outcomes**: Describe the population and methods used to measure and value outcomes, such as patient or population-based utility weights.
14. **Measurement and Valuation of Resources and Costs**: Describe how costs were valued, including data sources (e.g., hospital records, MOH tariffs).
15. **Currency, Price Date, and Conversion**: Report the dates of the estimated resource quantities and unit costs, plus the currency and year of conversion, ensuring cost transparency.
16. **Rationale and Description of Model**: If modeling is used, describe in detail why it was used and report if the model is publicly available and where it can be accessed, enabling replication.
17. **Analytics and Assumptions**: Describe any methods for analyzing or statistically transforming data, any extrapolation methods, and approaches for validating any model used, ensuring methodological clarity.
18. **Characterising Heterogeneity**: Describe any methods used for estimating how the results of the study vary for subgroups, addressing population diversity.
19. **Characterising Distributional Effects**: Describe how impacts are distributed across different individuals or adjustments made to reflect priority populations, ensuring equity considerations.
20. **Characterising Uncertainty**: Describe methods to characterize any sources of uncertainty in the analysis, such as sensitivity analyses, to assess result robustness.
21. **Approach to Engagement with Patients and Others Affected by the Study**: Describe any approaches to engage patients, service recipients, the general public, communities, or stakeholders (e.g., clinicians or payers) in the design of the study, promoting inclusivity.
22. **Study Parameters**: Report all analytic inputs (e.g., values, ranges, references) including uncertainty or distributional assumptions, ensuring all data are documented.
23. **Summary of Main Results**: Report the mean values for the main categories of costs and outcomes of interest and summarize them in the most appropriate overall measure, such as ICER.
24. **Effect of Uncertainty**: Describe how uncertainty about analytic judgments, inputs, or projections affects findings, including the effect of discount rate and time horizon choices, if applicable.
25. **Effect of Engagement with Patients and Others Affected by the Study**: Report on any difference patient/service recipient, general public, community, or stakeholder involvement made to the approach or findings of the study, highlighting their impact.
26. **Study Findings, Limitations, Generalizability, and Current Knowledge**: Report key findings, limitations, ethical or equity considerations not captured, and how these could impact patients, policy, or practice, providing a comprehensive discussion.
27. **Source of Funding**: Describe how the study was funded and any role of the funder in the identification, design, conduct, and reporting of the analysis, ensuring transparency.
28. **Conflicts of Interest**: Report authors‚Äô conflicts of interest according to journal or International Committee of Medical Journal Editors requirements, promoting accountability.

> **‚ÄúEach domain tells part of the story. CHEERS doesn‚Äôt ask if your results are correct, only if readers can understand what you did, why, and how.‚Äù**

CHEERS 2022 checklist is designed to ensure **transparency** and **comprehensibility** in reporting, not to evaluate the methodological validity of the study. Each domain and item contributes to a cohesive narrative, enabling stakeholders to understand the evaluation‚Äôs methods, findings, and implications for policy decisions.

---

## üî¨ 6. Focus on the Methods Section

This section delves into the critical importance of the **methods section** in economic evaluations, emphasizing its role as the **core component** that determines the **transparency**, **reproducibility**, and **policy relevance** of a study. The **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 checklist** dedicates **18 items** (items 4‚Äì21) to the methods section, covering essential aspects such as perspective, costing, modeling, and stakeholder engagement. By providing detailed and clear reporting of these elements, the methods section ensures that findings are **understandable** to stakeholders like policymakers and **reproducible** by researchers, enabling informed decision-making in contexts such as Malaysia‚Äôs health system. This section also presents examples of strong and weak reporting practices and poses a critical question to guide appraisal, equipping students with the skills to evaluate the quality of reporting in economic evaluations using CHEERS 2022.

### Why Focus on Methods?

The **methods section** is the **engine room** of an economic evaluation, serving as the foundation for its credibility and utility in health policy.

- The **methods section** is the **engine room** of an economic evaluation: It contains the technical details that underpin the study‚Äôs findings, making it the most critical component for assessing the validity and applicability of results.
- It determines whether findings are **understandable**, **reproducible**, and **policy-relevant**: Clear reporting ensures that policymakers (e.g., Malaysia‚Äôs **Ministry of Health** or **MaHTAS**) can comprehend the study‚Äôs approach, researchers can replicate it, and decision-makers can apply it to real-world contexts.
- CHEERS includes **18 items** under Methods (items 4‚Äì21), covering aspects like perspective, costing, modeling, and stakeholder engagement: These items address critical elements such as the study‚Äôs perspective, time horizon, data sources, and analytical methods, ensuring comprehensive documentation.

A well-reported methods section is essential for bridging the gap between research and policy, enabling stakeholders to trust and act on the findings of economic evaluations.

### Example CHEERS Items from the Methods Section

To illustrate the importance of transparent reporting, the table below compares **strong** and **weak/incomplete** reporting examples for key CHEERS items in the methods section. These examples highlight how detailed reporting enhances clarity and reproducibility, while vague reporting undermines the study‚Äôs utility.

|**CHEERS Item**|**Strong Reporting Example**|**Weak/Incomplete Example**|
|---|---|---|
|**Perspective (Item 8)**|‚ÄúA health system perspective was adopted, including only direct medical costs as per MaHTAS guidelines.‚Äù|‚ÄúCosts were included.‚Äù|
|**Time Horizon (Item 9)**|‚ÄúLifetime horizon was used to reflect long-term recurrence and survival.‚Äù|‚ÄúAnalysis was done for a few years.‚Äù|
|**Discount Rate (Item 10)**|‚ÄúBoth costs and QALYs were discounted at 3% annually, consistent with HTA norms.‚Äù|‚ÄúDiscounting was applied.‚Äù|
|**Health Outcomes (Item 11)**|‚ÄúQALYs were estimated using EQ-5D-5L with Malaysian value set.‚Äù|‚ÄúQALYs were used.‚Äù|
|**Costing Approach (Item 14)**|‚ÄúResource use was obtained from clinical records and unit costs were sourced from MOH tariffs.‚Äù|‚ÄúCosts were estimated.‚Äù|
|**Modelling Approach (Item 16)**|‚ÄúA Markov model with 1-year cycles simulated transitions between remission, relapse, and death.‚Äù|‚ÄúA model was used to project results.‚Äù|
|**Sensitivity Analysis (Item 20)**|‚ÄúOne-way and probabilistic sensitivity analyses were conducted on drug cost, utilities, and transition probabilities.‚Äù|‚ÄúSensitivity analysis was done.‚Äù|

- **Perspective (Item 8)**: Strong reporting specifies the perspective (e.g., health system) and aligns it with guidelines (e.g., MaHTAS), while weak reporting vaguely mentions costs without context.
- **Time Horizon (Item 9)**: Strong reporting justifies a lifetime horizon for capturing long-term outcomes, whereas weak reporting provides an ambiguous timeframe.
- **Discount Rate (Item 10)**: Strong reporting details the discount rate (e.g., 3%) and its alignment with HTA standards, while weak reporting fails to specify the rate or rationale.
- **Health Outcomes (Item 11)**: Strong reporting identifies the tool (e.g., EQ-5D-5L) and value set (e.g., Malaysian), ensuring clarity, while weak reporting is vague about QALY estimation.
- **Costing Approach (Item 14)**: Strong reporting details data sources (e.g., clinical records, MOH tariffs), enabling verification, while weak reporting lacks specificity.
- **Modelling Approach (Item 16)**: Strong reporting describes the model structure (e.g., Markov model with 1-year cycles) and states, while weak reporting omits details.
- **Sensitivity Analysis (Item 20)**: Strong reporting specifies the types (e.g., one-way, probabilistic) and parameters tested, while weak reporting is non-specific.

These examples demonstrate that **strong reporting** provides the detail needed for **transparency** and **reproducibility**, while **weak reporting** leaves stakeholders unable to assess or trust the findings.

### Critical Question

> **Could a policymaker or another researcher reproduce this study based on what‚Äôs reported in the methods section?**

This underscores the importance of the methods section in enabling **reproducibility**. A well-reported methods section should provide sufficient detail for policymakers to understand the study‚Äôs approach and for researchers to replicate it in other contexts. If key details‚Äîsuch as data sources, model structure, or analytical methods‚Äîare missing or unclear, the study‚Äôs findings cannot be verified or applied, reducing its **policy impact**. This question serves as a guiding principle for appraising economic evaluations using the CHEERS 2022 checklist, ensuring that the methods section meets the standards of **clarity** and **completeness**.

---

## üõ†Ô∏è 7. Applying CHEERS in Practice

This section provides a practical guide to applying the **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 checklist** to critically appraise economic evaluation studies. By outlining a systematic approach to reviewing studies section by section and introducing a **practical coding system**, this section equips students with the tools to evaluate the **transparency** and **completeness** of reporting in economic evaluations. These skills are essential for assessing whether studies meet the rigorous standards required by stakeholders, such as Health Technology Assessment (HTA) bodies, ensuring that findings are **understandable**, **reproducible**, and **policy-relevant**. Mastering this process enables public health professionals to identify high-quality studies and recognize reporting gaps, contributing to **evidence-based decision-making** in resource-constrained health systems.

### How to Use the CHEERS Checklist

The CHEERS 2022 checklist, with its **6 domains** and **28 items**, provides a structured framework for appraising economic evaluations. The following steps outline a systematic approach to applying the checklist, ensuring that each section of a study is evaluated for clarity and completeness:

1. **Read the Article Section by Section**:
    - **Title/Abstract ‚Üí Introduction ‚Üí Methods ‚Üí Results ‚Üí Discussion**: Review the study systematically, starting with the title and abstract to understand its scope, moving through the introduction to grasp its context, analyzing the methods for technical rigor, evaluating the results for clarity, and assessing the discussion for implications and limitations.
2. **Match Sections to CHEERS Items**:
    - **Use the 6 domains and 28 checklist items as a guide**: Align each section of the study with the corresponding CHEERS domain (e.g., Title & Abstract, Methods) and specific items (e.g., item 8 for perspective, item 10 for discount rate) to ensure all reporting requirements are addressed.
3. **Evaluate Each Item**:
    - ‚úÖ **Clearly and fully reported**?: Determine if the item is reported with sufficient detail to be understandable and reproducible (e.g., specifying a discount rate of 3% with justification).
    - üü° **Mentioned but unclear/incomplete**?: Assess whether the item is mentioned but lacks detail or clarity (e.g., stating ‚ÄúQALYs were used‚Äù without specifying the utility tool).
    - ‚ùå **Missing altogether**?: Identify if the item is entirely absent, undermining the study‚Äôs transparency (e.g., no mention of the study‚Äôs perspective).

This systematic approach ensures that evaluations are thoroughly assessed for **transparency**, enabling stakeholders to determine whether the study can be trusted and applied in policy contexts like Malaysia‚Äôs healthcare system.

### Practical Coding System

To facilitate a consistent and objective appraisal, the CHEERS checklist is supported by a **practical coding system** that categorizes the quality of reporting for each item. The following table outlines the symbols and their meanings:

|**Symbol**|**Meaning**|
|---|---|
|‚úÖ|Clearly and transparently reported|
|üü°|Mentioned, but unclear or incomplete|
|‚ùå|Not reported|

- **‚úÖ Clearly and transparently reported**: The item is fully documented with sufficient detail to allow understanding and replication (e.g., ‚ÄúA Markov model with 1-year cycles simulated transitions between remission, relapse, and death‚Äù).
- **üü° Mentioned, but unclear or incomplete**: The item is referenced but lacks critical details, making it difficult to assess or replicate (e.g., ‚ÄúA model was used to project results‚Äù without specifying the model type).
- **‚ùå Not reported**: The item is entirely absent, significantly undermining the study‚Äôs transparency and utility (e.g., no mention of the discount rate).

**Use this system to systematically critique economic evaluation studies**: By applying these symbols to each of the 28 CHEERS items, students can methodically evaluate a study‚Äôs reporting quality, identifying strengths and gaps. This approach is particularly valuable for assessing studies submitted to **HTA agencies** or journals, ensuring they meet the standards required for **policy-relevant** decision-making.

---

## üìñ 8. Appraising a Published Study

This section applies the **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 checklist** to critically appraise a published economic evaluation study, providing a practical demonstration of how to assess **transparency** and **completeness** in reporting. The study, focused on a lung cancer screening program in Germany, serves as a case study for evaluating reporting quality against the 28 CHEERS items. By reviewing the study‚Äôs background, objectives, methods, results, and discussion, students learn to identify strengths and gaps in reporting, ensuring that economic evaluations are **understandable**, **reproducible**, and **policy-relevant** for stakeholders. The completed appraisal table for all 28 CHEERS items integrates the partial appraisal from the original document (items 1‚Äì2) with assessments for items 3‚Äì28 based on the provided study details, equipping students with skills to contribute to **evidence-based health policy** decisions.

### Study Overview

The study under appraisal is a cost-utility analysis of a lung cancer screening program, offering a practical example for applying the CHEERS 2022 checklist.

- **Title**: _Cost-utility analysis of a potential lung cancer screening program for a high-risk population in Germany: A modelling approach_
- **Authors**: Hofer, F., Kauczor, H. U., & Stargardt, T.
- **Publication**: _Lung Cancer (Amsterdam, Netherlands)_, 124, 189‚Äì198 (2018).
- **DOI**: [10.1016/j.lungcan.2018.07.036](https://doi.org/10.1016/j.lungcan.2018.07.036)

This study provides a robust case for students to evaluate how well an economic evaluation reports its methods and findings, ensuring alignment with CHEERS standards for **transparency** and **policy utility**.

### Study Summary

The study evaluates the cost-effectiveness of a lung cancer screening program, detailing its background, objectives, methods, and results to inform health policy in Germany.

- **Background**: Lung cancer is the leading cause of cancer death in Germany. Evidence on the cost-effectiveness of screening programs is scarce, necessitating rigorous economic evaluations to guide policy decisions.
- **Objective**: Evaluate the cost-effectiveness of a population-based lung cancer screening program from a **public payer perspective** for a high-risk population (heavy smokers, aged 55‚Äì75), addressing a critical public health challenge.
- **Methods**:
    - Used **two Markov models** comparing annual screening vs. standard clinical care, simulating long-term outcomes.
    - **Population**: Heavy smokers (‚â•20 cigarettes/day), focusing on a high-risk group prone to lung cancer.
    - **Outcomes**: Costs, life years saved, **Quality-Adjusted Life Years (QALYs)**, capturing both quantity and quality of life.
    - **Model**: 60 cycles with a 3-month cycle length, allowing detailed simulation of disease progression.
    - **Sensitivity Analyses**: Deterministic and probabilistic analyses to test the robustness of results under varying assumptions.
- **Results**:
    - **Incremental Costs**: ‚Ç¨1,153 per person, indicating the additional cost of the screening program compared to standard care.
    - **Incremental Gains**: 0.06 life years and 0.04 QALYs per person, reflecting modest health benefits.
    - **ICER**: ‚Ç¨19,302 per life year saved and ‚Ç¨30,291 per QALY gained, though the original lecture document notes a truncated value (likely an error), which is clarified here from the study.

This summary provides the context and key findings, setting the stage for a CHEERS-based appraisal to evaluate reporting quality.

### CHEERS Appraisal

The CHEERS 2022 checklist is used to assess the **transparency** and **completeness** of the study‚Äôs reporting. The original lecture document provides appraisals for items 1‚Äì2, noting that the title is clear but lacks comparator details and the abstract is structured. Below is the complete appraisal table for all **28 CHEERS items**, integrating the provided appraisals for items 1‚Äì2 and completing appraisals for items 3‚Äì28 based on the study details provided, ensuring fidelity to the original content and the study‚Äôs text. Each item is evaluated using the coding system: ‚úÖ (clearly reported), üü° (unclear/incomplete), or ‚ùå (not reported).

|**CHEERS Item**|**Description**|**Appraisal**|**Remarks**|
|---|---|---|---|
|1. Title|Identify the study as an economic evaluation and specify the interventions|‚úÖ|Clear title but no mention of the comparator. The title identifies it as a cost-utility analysis but does not specify ‚Äústandard clinical care‚Äù as the comparator.|
|2. Abstract|Provide a structured summary that highlights context, key methods, results, and alternative analyses|‚úÖ|Structured abstract. The abstract clearly summarizes the background, objective, methods (Markov models, public payer perspective), results (ICERs), and sensitivity analyses.|
|3. Background & Objectives|Give the context for the study, the study question, and its practical relevance for decision-making|‚úÖ|Clearly reported. The introduction details lung cancer‚Äôs burden in Germany, the scarcity of cost-effectiveness evidence, and the objective to evaluate a screening program from a payer perspective.|
|4. Health Economic Analysis Plan|Indicate whether a health economic analysis plan was developed and where available|üü°|Mentioned but unclear. The study does not explicitly state whether a formal analysis plan was developed or where it is available, though methods are detailed.|
|5. Study Population|Describe characteristics of the study population|‚úÖ|Clearly reported. The study specifies heavy smokers (‚â•20 cigarettes/day, aged 55‚Äì75), with a cohort size of 1,600,270 based on German data.|
|6. Setting & Location|Provide relevant contextual information that may influence findings|‚úÖ|Clearly reported. The study specifies Germany‚Äôs statutory health insurance system and cites relevant trials (e.g., LUSI) for context.|
|7. Comparators|Describe the interventions or strategies being compared and why chosen|‚úÖ|Clearly reported. The study compares annual LDCT screening to standard clinical care, justified by the need to assess early detection benefits.|
|8. Perspective|State the perspective(s) adopted by the study and why chosen|‚úÖ|Clearly reported. The public payer perspective is explicitly stated, justified by its relevance to German statutory health insurers.|
|9. Time Horizon|State the time horizon for the study and why appropriate|‚úÖ|Clearly reported. A 15-year horizon (60 cycles of 3 months) is specified, appropriate for capturing long-term lung cancer outcomes, with sensitivity analysis testing a 20-year horizon.|
|10. Discount Rate|Report the discount rate(s) and reason chosen|‚úÖ|Clearly reported. Costs and QALYs are discounted at 3% annually, consistent with HTA norms, though the specific rationale is implied rather than detailed.|
|11. Selection of Outcomes|Describe what outcomes were used as the measure(s) of benefit(s) and harm(s)|‚úÖ|Clearly reported. Outcomes include costs, life years saved, and QALYs, with no explicit mention of harms (e.g., radiation risks) but addressed in limitations.|
|12. Measurement of Outcomes|Describe how outcomes used to capture benefit(s) and harm(s) were measured|üü°|Mentioned but incomplete. QALYs are measured using pooled quality-of-life scores from a meta-analysis, but specific tools (e.g., EQ-5D) are not mentioned. Harms (e.g., dis-utilities from false positives) are considered in sensitivity analysis but not detailed.|
|13. Valuation of Outcomes|Describe the population and methods used to measure and value outcomes|üü°|Mentioned but incomplete. QALYs use pooled scores from a meta-analysis, but the population (e.g., German-specific) and valuation methods are not fully detailed.|
|14. Measurement and Valuation of Resources and Costs|Describe how costs were valued|‚úÖ|Clearly reported. Costs for diagnosis, treatment, and aftercare are sourced from German reimbursement catalogues and validated studies (e.g., Schwarzkopf et al.).|
|15. Currency, Price Date, and Conversion|Report the dates of the estimated resource quantities and unit costs, plus the currency and year of conversion|üü°|Mentioned but incomplete. Costs are in euros, with some based on 2016 prices, but specific dates for all resource quantities are not fully reported.|
|16. Rationale and Description of Model|If modeling is used, describe in detail and why used|‚úÖ|Clearly reported. Two Markov models are described (natural history and treatment/aftercare), with rationale for capturing disease progression and treatment paths, though public availability is not stated.|
|17. Analytics and Assumptions|Describe any methods for analyzing or statistically transforming data, any extrapolation methods, and approaches for validating any model used|‚úÖ|Clearly reported. Bayesian calibration with a Metropolis Hastings algorithm is used for transition probabilities, validated by expert consultation and German data.|
|18. Characterising Heterogeneity|Describe any methods used for estimating how results vary for subgroups|‚ùå|Not reported. The study does not explore subgroup variations (e.g., by age or smoking duration), though it acknowledges data limitations.|
|19. Characterising Distributional Effects|Describe how impacts are distributed across different individuals or adjustments made to reflect priority populations|‚ùå|Not reported. No discussion of distributional impacts or priority populations, despite the focus on high-risk smokers.|
|20. Characterising Uncertainty|Describe methods to characterize any sources of uncertainty in the analysis|‚úÖ|Clearly reported. Deterministic and probabilistic sensitivity analyses test parameters like screening intervals and costs, with results presented in tornado diagrams and Monte Carlo simulations.|
|21. Approach to Engagement with Patients and Others Affected by the Study|Describe any approaches to engage patients, service recipients, or stakeholders in the design of the study|‚ùå|Not reported. No mention of patient or stakeholder engagement in study design.|
|22. Study Parameters|Report all analytic inputs (e.g., values, ranges, references) including uncertainty or distributional assumptions|‚úÖ|Clearly reported. Key parameters (e.g., transition probabilities, costs, QALYs) are detailed with sources and distributions (e.g., beta, gamma) for sensitivity analyses.|
|23. Summary of Main Results|Report the mean values for the main categories of costs and outcomes of interest and summarize them in the most appropriate overall measure|‚úÖ|Clearly reported. Results include incremental costs (‚Ç¨1,153), life years (0.06), QALYs (0.04), and ICERs (‚Ç¨19,302/LY, ‚Ç¨30,291/QALY), with budget impact estimates.|
|24. Effect of Uncertainty|Describe how uncertainty about analytic judgments, inputs, or projections affects findings|‚úÖ|Clearly reported. Sensitivity analyses show robust ICERs (e.g., ‚Ç¨16,260‚Äì‚Ç¨31,000/LY), with key drivers like cancer incidence and screening costs identified.|
|25. Effect of Engagement with Patients and Others Affected by the Study|Report on any difference patient/service recipient, general public, community, or stakeholder involvement made to the approach or findings|‚ùå|Not reported. No discussion of stakeholder engagement impacts, consistent with item 21.|
|26. Study Findings, Limitations, Generalizability, and Current Knowledge|Report key findings, limitations, ethical or equity considerations not captured, and how these could impact patients, policy, or practice|‚úÖ|Clearly reported. The discussion covers findings, limitations (e.g., radiation exposure, overdiagnosis), and policy implications, though equity is not deeply explored.|
|27. Source of Funding|Describe how the study was funded and any role of the funder in the identification, design, conduct, and reporting of the analysis|‚úÖ|Clearly reported. Funded by Siemens Healthcare GmbH, with no involvement in study design or reporting.|
|28. Conflicts of Interest|Report authors‚Äô conflicts of interest according to journal or International Committee of Medical Journal Editors requirements|‚úÖ|Clearly reported. Authors declare no conflicts of interest, meeting journal standards.|

This appraisal table demonstrates the application of the CHEERS 2022 checklist to evaluate the reporting quality of Hofer et al. (2018). The study excels in most areas, with **clear reporting** (‚úÖ) for 17 items, including title, abstract, methods, results, and funding. However, **incomplete reporting** (üü°) for items like outcome valuation and currency details, and **missing reporting** (‚ùå) for heterogeneity, distributional effects, and stakeholder engagement, highlight gaps that could limit reproducibility or policy relevance. These findings reinforce the importance of **transparent reporting** to ensure economic evaluations are **usable** for decision-making in contexts like Malaysia‚Äôs healthcare system.

---

## üö® 9. Top 5 Common Reporting Gaps

This section identifies the **top five common reporting gaps** in economic evaluations, highlighting frequent deficiencies that undermine the **transparency**, **reproducibility**, and **policy relevance** of studies. These gaps, often observed in published economic evaluations, can prevent stakeholders such as policymakers, researchers, and Health Technology Assessment (HTA) agencies like Malaysia‚Äôs **MaHTAS** from fully understanding or trusting study findings. By detailing each gap, its implications, and illustrative examples, this section equips students with the ability to recognize and address these issues when appraising studies using the **CHEERS 2022 checklist**. Understanding these gaps is crucial for ensuring that economic evaluations are **clear**, **complete**, and **actionable** in informing **evidence-based health policy** decisions, particularly in resource-constrained settings like Malaysia‚Äôs healthcare system.

### Common Reporting Deficiencies in Economic Evaluations

The following are the most frequent reporting deficiencies in economic evaluations, with implications for transparency and policy relevance. Each gap is presented with its **issue**, **why it matters**, and an **example** to illustrate its impact:

1. **Perspective Not Stated**:
    
    - **Issue**: Studies fail to clarify whether the perspective is societal, payer, or provider, leaving ambiguity about the scope of costs and outcomes considered.
    - **Why It Matters**: Perspective determines which costs and outcomes should be included, directly affecting the study‚Äôs relevance and applicability. For instance, a societal perspective includes indirect costs like productivity losses, while a payer perspective focuses on reimbursed costs.
    - **Example**: A study includes only drug costs but claims societal relevance, misleading readers about the comprehensiveness of the analysis and potentially skewing policy decisions.
2. **No Justification for Time Horizon or Discount Rate**:
    
    - **Issue**: Time horizons may be chosen arbitrarily, and discounting may be unexplained or omitted entirely, reducing the credibility of long-term projections.
    - **Why It Matters**: Short timeframes can misrepresent chronic disease costs and benefits, while discounting ensures appropriate weighting of future outcomes. Without justification, stakeholders cannot assess the appropriateness of these choices.
    - **Example**: Lifetime outcomes are modeled without reported discounting, making it impossible to evaluate how future costs and benefits were valued, potentially inflating results.
3. **Omission of Sensitivity Analysis**:
    
    - **Issue**: Sensitivity analyses are often missing or inadequately reported, leaving uncertainty in results unaddressed.
    - **Why It Matters**: Policymakers need to understand how uncertainty affects conclusions to make informed decisions. Sensitivity analysis tests the robustness of results, ensuring reliability across varying assumptions.
    - **Example**: A base-case Incremental Cost-Effectiveness Ratio (ICER) is reported without robustness testing, leaving policymakers unsure if the results hold under different conditions.
4. **Incomplete Model Structure Explanation**:
    
    - **Issue**: Models (e.g., decision trees, Markov models) lack details on states, transitions, or cycle length, obscuring the analytical framework.
    - **Why It Matters**: Transparency in model structure allows replication and critical appraisal, ensuring that the study‚Äôs methodology is verifiable and trustworthy.
    - **Example**: A Markov model is used without a diagram or state logic provided, preventing researchers from understanding or replicating the model‚Äôs design.
5. **Utility Sources Not Reported**:
    
    - **Issue**: Quality-Adjusted Life Year (QALY) calculations lack details on instruments (e.g., EQ-5D, SF-6D) or population-specific value sets, reducing transparency in outcome measurement.
    - **Why It Matters**: Utility weights vary by setting and significantly impact QALY estimates, affecting the study‚Äôs conclusions and comparability across contexts.
    - **Example**: A study states ‚Äúutility weights from the literature‚Äù without citation, leaving readers unable to verify the source or appropriateness of the weights.

### Implications for Transparency and Policy Relevance

These reporting gaps have significant implications for the **transparency** and **policy relevance** of economic evaluations:

- **Reduced Trust**: Incomplete or unclear reporting undermines confidence among stakeholders, such as Malaysia‚Äôs **Ministry of Health** or **MaHTAS**, making it difficult to rely on the study for decision-making.
- **Limited Reproducibility**: Missing details (e.g., model structure, utility sources) prevent other researchers from replicating the study, reducing its scientific credibility.
- **Inhibited Policy Application**: Without clear reporting, policymakers cannot adapt findings to local contexts (e.g., Malaysia‚Äôs healthcare system) or make informed resource allocation decisions, such as prioritizing cancer screening over other interventions.
- **Potential for Misleading Decisions**: Gaps like omitted sensitivity analyses or unstated perspectives can lead to incorrect conclusions, potentially resulting in inefficient or inequitable health policies.

To address these gaps, the **CHEERS 2022 checklist** provides a structured framework to ensure that all critical elements are reported clearly, enhancing the **usability** and **impact** of economic evaluations in health policy.

### Summary Table: Top 5 Common Reporting Gaps

The following table consolidates the key reporting gaps, their implications, and examples to provide a quick reference for students appraising economic evaluations:

|**Reporting Gap**|**Issue**|**Why It Matters**|**Example**|
|---|---|---|---|
|Perspective Not Stated|Fails to clarify societal, payer, or provider perspective|Determines which costs/outcomes are included|Only drug costs included but claims societal relevance|
|No Justification for Time Horizon or Discount Rate|Arbitrary timeframes or unexplained/omitted discounting|Short timeframes misrepresent chronic disease impacts; discounting weights future outcomes|Lifetime outcomes modeled without reported discounting|
|Omission of Sensitivity Analysis|Missing or inadequate reporting of sensitivity analyses|Policymakers need uncertainty assessment for robust conclusions|Base-case ICER reported without robustness testing|
|Incomplete Model Structure Explanation|Lacks details on model states, transitions, or cycle length|Transparency needed for replication and appraisal|Markov model used without diagram or state logic|
|Utility Sources Not Reported|QALY calculations lack instrument or value set details|Utility weights impact QALY estimates and comparability|‚ÄúUtility weights from the literature‚Äù without citation|

This table highlights the critical nature of these gaps and their impact on the **credibility** and **utility** of economic evaluations, emphasizing the need for **transparent reporting** to support **evidence-based health policy**.

---

## üåç 10. Why Reporting Quality Equals Policy Impact

This section underscores the critical link between **reporting quality** and the **policy impact** of economic evaluations, emphasizing that **transparency** and **clarity** are essential for informing health policy decisions. Economic evaluations guide pivotal decisions in **Health Technology Assessments (HTAs)**, **budget allocation**, **reimbursement**, and **service prioritization**, but their effectiveness hinges on clear reporting. **Poor reporting** undermines usability, regardless of a study‚Äôs methodological validity, as policymakers cannot trust or apply unclear findings. The section also highlights the **local relevance** of the **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022** in Malaysia and the region, where HTA bodies like **MaHTAS** increasingly demand transparent reporting. By understanding these concepts, students will appreciate how CHEERS bridges the gap between research and policy, ensuring evaluations are **actionable** and **trustworthy** in resource-constrained health systems like Malaysia‚Äôs.

### Role of Economic Evaluations in Health Policy

Economic evaluations inform critical health policy decisions, providing evidence to guide resource allocation and prioritize interventions that maximize health outcomes within limited budgets. The following areas highlight their importance:

- **Health Technology Assessments (HTAs)**: Economic evaluations assess the cost-effectiveness of new technologies, drugs, or procedures, informing decisions about their adoption in health systems like Malaysia‚Äôs **MyHTA** framework.
- **Budget impact analysis** and **resource allocation**: They help policymakers allocate finite resources efficiently, such as deciding whether to fund cancer screening programs or expand hospital facilities.
- **Reimbursement decisions** and **coverage recommendations**: Evaluations guide decisions about which interventions to reimburse, such as including treatments in Malaysia‚Äôs **Peka B40** program for low-income groups.
- **National clinical guidelines** and **service prioritization**: They inform the development of guidelines and prioritization of services, ensuring alignment with national health priorities, such as addressing non-communicable diseases.

**Poor reporting** undermines usability, regardless of result validity, as policymakers cannot trust or apply unclear studies. Without transparent reporting, even robust evaluations fail to influence policy, as stakeholders like Malaysia‚Äôs **Ministry of Health** or **MaHTAS** require clear, reproducible evidence to make informed decisions.

### Local Relevance (Malaysia & Region)

The **CHEERS 2022 checklist** is increasingly vital in Malaysia and the region, where transparent reporting is a prerequisite for integrating economic evaluations into health policy.

- **MaHTAS** (Ministry of Health Malaysia) and other HTA bodies (e.g., **HITAP** in Thailand, **NICE** in the UK) increasingly require **CHEERS-compliant reporting**: These agencies demand clear and complete reporting to ensure evaluations meet rigorous standards for policy inclusion.
- **Impact**: Transparent reporting strengthens inclusion in:
    - **MyHTA reports**: Malaysia‚Äôs HTA reports, which assess interventions for adoption in the public health system, rely on CHEERS-compliant studies to ensure credibility.
    - **Pharmacoeconomic documents**: These documents, used to evaluate drug cost-effectiveness, require transparent reporting to inform reimbursement decisions.
    - **Regional policy dialogues**: Transparent evaluations facilitate cross-country discussions, such as those involving ASEAN health systems, to harmonize health policies.
- **Key Insight**: **‚ÄúHealth systems don‚Äôt make million-ringgit decisions on vague data. CHEERS bridges the gap between research and policy.‚Äù** This insight emphasizes that clear reporting is essential for translating research into actionable policy, ensuring that high-stakes decisions in Malaysia‚Äôs healthcare system are based on reliable, transparent evidence.

### Summary Table: Policy Impact of Transparent Reporting

The following table summarizes how transparent reporting via CHEERS enhances the policy impact of economic evaluations, with examples relevant to Malaysia:

|**Policy Area**|**Role of Economic Evaluations**|**Impact of Transparent Reporting**|**Malaysia Example**|
|---|---|---|---|
|Health Technology Assessments (HTAs)|Assess cost-effectiveness of new interventions|Ensures findings are clear and reproducible for adoption decisions|MaHTAS evaluating a new cancer drug for MyHTA inclusion|
|Budget Impact & Resource Allocation|Guide efficient allocation of resources|Clarifies trade-offs for prioritizing interventions|Deciding between cancer screening vs. ICU bed expansion|
|Reimbursement & Coverage|Inform funding decisions for treatments|Provides transparent evidence for reimbursement policies|Including treatments in Peka B40 program|
|National Guidelines & Prioritization|Shape clinical guidelines and service priorities|Ensures evidence is trustworthy for policy development|Prioritizing non-communicable disease programs|

This table highlights how **transparent reporting**, as facilitated by CHEERS 2022, ensures that economic evaluations are **actionable**, **trustworthy**, and **aligned** with Malaysia‚Äôs health policy needs, maximizing their impact on decision-making.

---

## üóùÔ∏è 11. Final Key Takeaways

The lecture underscores how mastering the application of CHEERS equips students to critically appraise studies, identify deficiencies, and contribute to **evidence-based health policy** decisions in Malaysia and beyond, particularly in resource-constrained settings like Malaysia‚Äôs healthcare system. These takeaways provide a foundation for public health professionals to bridge the gap between research and policy, maximizing health outcomes within limited resources. By summarizing the purpose of CHEERS, the process of appraising studies, common reporting gaps, and the impact of transparent reporting, this section reinforces the importance of clear communication in ensuring that economic evaluations are **trustworthy** and **actionable**. 

### Key Insights from CHEERS 2022

The **CHEERS 2022 checklist** is a reporting checklist that enhances **clarity**, **transparency**, and **policy usability** of economic evaluations, ensuring that studies are accessible and actionable for stakeholders such as policymakers, researchers, and Health Technology Assessment (HTA) agencies like Malaysia‚Äôs **MaHTAS**.

- **Clarity**: CHEERS ensures that all critical components of an economic evaluation‚Äîsuch as methods, results, and assumptions‚Äîare clearly documented, making studies understandable to diverse audiences.
- **Transparency**: By requiring detailed reporting of elements like perspective and sensitivity analyses, CHEERS promotes openness, allowing stakeholders to verify and trust the findings.
- **Policy Usability**: Transparent reporting ensures that evaluations can be applied to real-world decisions, such as reimbursement or resource allocation, enhancing their impact on health policy.

### Appraising with CHEERS

**Appraising with CHEERS** involves a systematic evaluation of how well a study communicates its methods and findings, complementing technical peer review while being equally essential for policy relevance.

- Assesses **what was done** and **how clearly it was communicated**: CHEERS evaluates whether a study‚Äôs methodology, data sources, and results are clearly reported, ensuring stakeholders can understand the analysis without needing to assess its technical validity.
- Complements technical peer review but is equally essential: While peer review focuses on methodological rigor, CHEERS appraisal ensures that the study‚Äôs reporting is transparent and reproducible, making it usable for decision-making in contexts like Malaysia‚Äôs **MyHTA** reports.

### Common Reporting Gaps

**Common reporting gaps** in economic evaluations can significantly undermine their credibility and utility, highlighting areas where transparency is often lacking.

- Missing perspective, discounting, and sensitivity analyses: Failure to specify the perspective (e.g., societal, payer), justify discount rates, or conduct sensitivity analyses reduces the study‚Äôs reproducibility and reliability.
- Poor explanation of models and QALY derivation: Incomplete details about model structures (e.g., states, transitions) or QALY calculation methods (e.g., utility instruments) hinder critical appraisal and application.

These gaps can prevent policymakers from trusting or applying study findings, emphasizing the need for **CHEERS-compliant reporting** to address these deficiencies.

### Impact of Transparent Reporting

**Impact of Transparent Reporting**: Transparent reporting, as facilitated by CHEERS 2022, builds **stronger trust** and **increases uptake** in policy decisions, ensuring that economic evaluations effectively inform health policy.

- Builds **stronger trust**: Clear and complete reporting reassures stakeholders, such as Malaysia‚Äôs **Ministry of Health**, that the study‚Äôs findings are reliable and verifiable.
- Increases **uptake in policy decisions**: Transparent evaluations are more likely to be adopted in HTA processes, reimbursement decisions, and national guidelines, as they provide actionable evidence for resource allocation.

### Summary and Implications

This lecture underscores the importance of **transparent reporting** in economic evaluations using the **CHEERS 2022 checklist**. By mastering its application, students can critically appraise studies, identify reporting gaps, and contribute to **evidence-based health policy** decisions in Malaysia and beyond. The ability to evaluate and ensure reporting quality empowers public health professionals to bridge the gap between research and policy, ensuring that economic evaluations are **trustworthy**, **reproducible**, and **impactful** in optimizing health outcomes within resource constraints.

### Summary Table: Key Takeaways and Their Policy Impact

The following table consolidates the key takeaways and their implications for health policy, particularly in Malaysia‚Äôs context:

|**Key Takeaway**|**Description**|**Policy Impact**|**Malaysia Example**|
|---|---|---|---|
|CHEERS Enhances Clarity, Transparency, Usability|Ensures studies are clear, transparent, and actionable|Enables policymakers to trust and apply findings|MaHTAS uses CHEERS-compliant studies for MyHTA reports|
|Appraising with CHEERS|Assesses clarity of communication, complements peer review|Ensures studies are reproducible for policy use|Evaluating studies for Peka B40 reimbursement|
|Common Reporting Gaps|Missing perspective, discounting, sensitivity analyses, model details|Reduces trust and applicability if not addressed|Gaps in QALY derivation limit pharmacoeconomic document use|
|Transparent Reporting Impact|Builds trust, increases policy uptake|Enhances evidence-based decision-making|Strengthens regional policy dialogues in ASEAN|

This table highlights how CHEERS 2022 facilitates **evidence-based policymaking**, ensuring that economic evaluations are **clear**, **trustworthy**, and **actionable** in Malaysia‚Äôs healthcare system.

---

## üìù Self-Assessment Questions

## üìö Short Answer Questions

These questions test **conceptual understanding** of key terms and principles from the lecture, ensuring students grasp foundational concepts related to CHEERS 2022 and economic evaluations.

1. **What is the primary purpose of the CHEERS 2022 checklist?**
    
    - _Hint_: Consider its role in relation to study quality and stakeholder needs.
2. **Name the six domains of the CHEERS 2022 checklist and provide one example of a reporting item for each.**
    
    - _Hint_: Refer to the domains that structure the checklist‚Äôs 28 items.
3. **Explain the difference between micro-costing and gross costing in economic evaluations.**
    
    - _Hint_: Focus on their level of detail and data requirements.
4. **What does the Incremental Cost-Effectiveness Ratio (ICER) measure, and how is it interpreted using thresholds?**
    
    - _Hint_: Include the formula and its comparison to benchmarks like GDP per capita.
5. **Identify two common reporting gaps in economic evaluations and explain why they undermine policy relevance.**
    
    - _Hint_: Consider gaps like perspective or sensitivity analysis and their impact on trust.

## üî¢ Calculation-based Questions

These questions assess **quantitative applications**, requiring students to apply economic evaluation principles, such as calculating the **ICER**, to test their ability to interpret and manipulate data.

1. **ICER Calculation for a New Drug**:
    
    - A new diabetes drug costs RM75,000 per patient annually and yields 0.6 additional QALYs compared to standard care, which costs RM30,000 per patient annually and yields 0.2 QALYs. Calculate the ICER.
    - _Formula_:  
        $$\text{ICER} = \frac{\text{Incremental Cost}}{\text{Incremental QALYs}}$$
    - _Task_: Show your calculations and express the ICER in RM per QALY.
2. **Discounting Future Costs**:
    
    - A cancer screening program incurs a cost of RM100,000 in year 5. Using a discount rate of 3%, calculate the present value of this cost.
    - _Formula_:  
        $$\text{Present Value} = \frac{\text{Future Value}}{(1 + r)^n}$$  
        where ( r ) is the discount rate and ( n ) is the number of years.
    - _Task_: Provide the discounted cost, rounded to two decimal places.
3. **Sensitivity Analysis Impact**:
    
    - A study reports an ICER of RM80,000 per QALY for a new vaccine. A one-way sensitivity analysis shows that if the vaccine cost increases by 20%, the ICER rises to RM96,000 per QALY. Calculate the percentage increase in the ICER.
    - _Task_: Show your calculations using:  
        $$\text{\% Change} = \frac{\text{New ICER} - \text{Original ICER}}{\text{Original ICER}} \times 100\%$$

## ‚úçÔ∏è Short-Essay Questions

These questions require students to apply **CHEERS 2022 concepts** to practical scenarios, demonstrating **conceptual understanding** and **problem-solving skills** in health policy contexts.

1. **Evaluating Reporting Gaps in a Malaysian Context**:
    
    - A study evaluating a new hypertension drug in Malaysia claims cost-effectiveness but omits the perspective and sensitivity analysis. Using CHEERS 2022, explain how these gaps affect its usability for **MaHTAS** in deciding whether to include the drug in the **Peka B40** program. Suggest how the study could improve its reporting.
    - _Task_: Discuss the implications of these gaps and recommend specific CHEERS items to address them (150‚Äì200 words).
2. **Importance of the Methods Section**:
    
    - Why is the methods section considered the ‚Äúengine room‚Äù of an economic evaluation? Using two CHEERS items (e.g., perspective, modeling), explain how clear reporting in these areas supports **evidence-based policy** decisions in Malaysia‚Äôs healthcare system.
    - _Task_: Provide examples of strong vs. weak reporting and their policy implications (150‚Äì200 words).
3. **Adapting a Study to Malaysia**:
    
    - A European study on a cancer screening program reports a favorable ICER but lacks details on utility sources and time horizon justification. Discuss how these reporting gaps could hinder its adaptation to Malaysia‚Äôs healthcare system and propose how CHEERS 2022 can guide improvements.
    - _Task_: Identify specific CHEERS items and their relevance to Malaysia‚Äôs context (150‚Äì200 words).

## üß† Structured Case Study Questions

These questions require students to analyze complex scenarios, providing **critical analysis** and **policy recommendations** based on a case study, with **sub-questions** to structure responses.

**Case Study: Appraising a Tuberculosis (TB) Screening Program Study**  
A study evaluates a TB screening program in Malaysia using a Markov model, reporting an ICER of RM60,000 per QALY from a health system perspective. It includes costs (RM1,500/person), outcomes (0.05 QALYs gained), and sensitivity analyses but omits details on the discount rate, utility valuation method, and stakeholder engagement. The study aims to inform **MaHTAS** for inclusion in Malaysia‚Äôs national TB control program.

1. **Appraisal Using CHEERS 2022**:
    
    - **a)** Apply the CHEERS 2022 checklist to evaluate the study‚Äôs reporting quality for items 8 (Perspective), 10 (Discount Rate), 13 (Valuation of Outcomes), and 21 (Stakeholder Engagement). Use the coding system (‚úÖ, üü°, ‚ùå).
    - **b)** Discuss how each identified gap affects the study‚Äôs **policy relevance** for MaHTAS.
    - **Task**: Provide a table summarizing the appraisal and a 100‚Äì150 word discussion.
2. **Policy Recommendations**:
    
    - **a)** Based on the appraisal, recommend specific improvements to the study‚Äôs reporting to meet CHEERS 2022 standards.
    - **b)** Propose how MaHTAS could use the improved study to decide on TB screening program inclusion, considering Malaysia‚Äôs resource constraints.
    - **Task**: Provide recommendations in 150‚Äì200 words, linking to CHEERS items.
3. **Adapting to Local Context**:
    
    - **a)** Identify two reporting gaps that could hinder adapting the study to rural Malaysian settings.
    - **b)** Suggest how addressing these gaps could improve the study‚Äôs applicability for Malaysia‚Äôs **Ministry of Health**.
    - **Task**: Provide a 100‚Äì150 word response with specific CHEERS-based solutions.

## üåê Open-Ended Long Essay Questions

These questions require **in-depth analysis** to address complex healthcare challenges, encouraging **critical thinking**, **synthesis**, and **policy recommendations** with a focus on **Malaysia-specific** and **global applications**.

1. **Enhancing Policy Impact Through CHEERS in Malaysia**:
    
    - Discuss how the CHEERS 2022 checklist can enhance the policy impact of economic evaluations in Malaysia‚Äôs healthcare system, particularly for **Peka B40** and **non-communicable disease (NCD)** programs. Analyze three common reporting gaps (e.g., perspective, sensitivity analysis) and their implications for trust and uptake. Propose strategies to ensure CHEERS compliance in Malaysian studies, drawing on global HTA practices (e.g., NICE, HITAP).
    - _Task_: Provide a 500‚Äì600 word essay, integrating Malaysia-specific and global perspectives.
2. **Addressing Reporting Gaps for NCD Interventions**:
    
    - Evaluate the challenges of reporting economic evaluations for NCD interventions (e.g., diabetes, hypertension) in Malaysia, focusing on the top five common reporting gaps identified in the lecture. Discuss how these gaps affect the adoption of NCD interventions in Malaysia‚Äôs health system and propose a framework for researchers to improve reporting using CHEERS 2022. Include global examples to support your recommendations.
    - _Task_: Provide a 500‚Äì600 word essay, emphasizing critical analysis and policy solutions.
3. **Global and Local Applications of CHEERS 2022**:
    
    - Analyze how the CHEERS 2022 checklist can be applied to ensure economic evaluations are relevant for both Malaysia‚Äôs resource-constrained health system and global health policy contexts. Discuss the role of transparent reporting in facilitating regional policy dialogues (e.g., ASEAN) and global HTA harmonization. Provide specific recommendations for Malaysian researchers to align studies with CHEERS, addressing at least three checklist items and their policy implications.
    - _Task_: Provide a 500‚Äì600 word essay, synthesizing local and global applications.

---
