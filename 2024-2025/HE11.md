# Health Economics: Economic Evaluation III â€“ Appraising Economic Evaluations Using CHEERS 2022  

**MQB7014: Health Economics**  
**Master of Public Health (MPH) Programme, University of Malaya**  
**Prepared by: Dr Ainol Haniza Kherul Anuwar**  
**DDS (UGM), MCOH (Distinction) (Malaya), DrDPH (Malaya)**  
**Department of Community Oral Health & Clinical Prevention, Faculty of Dentistry, Universiti Malaya**  
**Credit: Prof Dr Maznah Dahlui, Department of Social & Preventive Medicine, Faculty of Medicine, Universiti Malaya**  
**Lecture Date: June 12, 2025**

---

The content focuses on the **CHEERS 2022 checklist** as a tool for appraising the quality of **economic evaluation reporting**, ensuring **transparency**, **clarity**, and **policy relevance**. 

---

# ğŸ“š 1. Introduction to CHEERS 2022

**Economic Evaluation III** focuses on critically appraising **economic evaluations** using the **Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 checklist**. Delivered on **June 12, 2025**, this lecture equips students with tools to assess the **quality**, **transparency**, and **reproducibility** of published economic evaluation studies, ensuring they are **policy-relevant** for health systems, including Malaysiaâ€™s. The **CHEERS 2022 checklist** is a standardized framework widely used by **Health Technology Assessment (HTA)** agencies, journals, and researchers to enhance reporting quality.

### ğŸ¯ Learning Outcomes
By the end of this session, students should be able to:
- **Understand** the purpose and structure of the **CHEERS 2022 checklist**.
- **Identify** the key domains of **high-quality economic evaluation reporting**.
- **Apply** CHEERS to appraise published **economic evaluation studies**.
- **Recognize** common **reporting gaps** and their implications.

---

## ğŸ©º 2. Recap of Economic Evaluation II

### ğŸ“– Key Concepts from EE II

- **Costing**:
  - **Types**: 
    - **Direct Medical**: Costs incurred by the health system/provider (e.g., chemotherapy drugs, oncologist fees, infusion room, lab tests) ğŸ©º.
    - **Direct Non-Medical**: Non-medical expenses due to seeking care (e.g., patient travel, parking, accommodation) ğŸš—.
    - **Indirect**: Productivity losses due to illness or treatment (e.g., sick leave, early retirement) ğŸ’¼.
    - **Intangible**: Non-financial costs hard to quantify (e.g., anxiety, pain, hair loss stigma) ğŸ˜Ÿ.
  - **Methods**: 
    - **Micro-Costing**: Detailed itemization of resources, used for high precision (e.g., clinical trials).
    - **Gross-Costing**: Average cost per service unit, used for budget planning or secondary data.
  - **Perspective**: Determines which **costs** are included (e.g., societal includes all costs, health system focuses on medical costs).
- **Outcome Measurement**:
  - **Cost-Effectiveness Analysis (CEA)**: Uses **natural units** (e.g., life-years gained, cases prevented).
  - **Cost-Utility Analysis (CUA)**: Uses **utility-based measures** like **Quality-Adjusted Life Years (QALYs)** or **Disability-Adjusted Life Years (DALYs)**.
  - **Cost-Benefit Analysis (CBA)**: Outcomes monetized (e.g., RM value of productivity).
  - **Utility Values**: Essential for QALY calculations, often derived from tools like **EQ-5D** âš–ï¸.

### ğŸ“œ Key Takeaway

- *â€œEven the most precise analysis is only as useful as its clarity; economic evaluation must be transparent to be usable.â€*  
  - Transparent reporting ensures **policymakers**, **HTA agencies**, and **researchers** can trust and apply evaluation results.

---

## ğŸ“‹ 3. Why Critical Appraisal Matters

### ğŸ“– The Problem

Many **economic evaluations** appear robust, with **statistically rigorous models** and **impressive Incremental Cost-Effectiveness Ratios (ICERs)**, but **incomplete reporting** undermines their **credibility**. Without clear reporting, decision-makers cannot assess the **validity** or **relevance** of findings.

- **Issues**:
  - Evaluations may look **rigorous** and use **advanced modeling** but fail to report **key details**.
  - **Example**: A study stating â€œQALYs were estimatedâ€ without specifying:
    - **Utility tool** (e.g., EQ-5D, SF-6D).
    - **Preferences** (e.g., whose values were used).
    - **Time horizon** or **discounting** method.
  - Such omissions make even a **correct ICER** uninterpretable.

### ğŸŒŸ Why It Matters for Public Health and Policy

- **Poorly reported evaluations** hinder **decision-making** in:
  - **Health Technology Assessments (HTA)**.
  - **Budget impact analysis** and **resource allocation**.
  - **Reimbursement decisions** and **coverage recommendations**.
  - **National clinical guidelines** and **service prioritization**.
- **Key Message**: *â€œA strong economic evaluation is not just about having the right model, itâ€™s about reporting it clearly, so others can evaluate and trust your results.â€*

---

## ğŸ“š 4. What is CHEERS 2022?

### ğŸ“– Overview

- **CHEERS (Consolidated Health Economic Evaluation Reporting Standards)**: A **reporting checklist** that enhances **clarity**, **transparency**, and **policy usability** of economic evaluations.
- **Purpose**: Ensures every essential part of an economic evaluation is **visible**, **understandable**, and **usable** for stakeholders like **HTA agencies** (e.g., NICE, MaHTAS), **peer-reviewed journals**, and **researchers**.
- **Key Takeaway**: *â€œIf itâ€™s not reported, it didnâ€™t happen. CHEERS ensures every essential part of an economic evaluation is visible, understandable, and usable.â€*

### ğŸ“‹ Role in Policy and Research

- **Widely Used By**:
  - **HTA agencies** (e.g., NICE in the UK, MaHTAS in Malaysia).
  - **Peer-reviewed journals** for manuscript preparation.
  - **Researchers** to align with **evidence transparency** in health system decision-making.

---

## ğŸ§  5. CHEERS 2022 Structure

### ğŸ“– Overview

The **CHEERS 2022 checklist** comprises **28 items** organized into **6 domains** to guide the reporting of **economic evaluations**. While the full checklist is not detailed in the slides, key items are highlighted, particularly from the **Methods section**, which is described as the **â€œengine roomâ€** of an evaluation.

### ğŸ“‹ Sample CHEERS Items (Methods Section)

- **Focus**: The **Methods section** determines whether findings are **understandable**, **reproducible**, and **policy-relevant**.
- **Examples**:

| **CHEERS Item** | **Strong Reporting Example** | **Weak/Incomplete Example** |
|-----------------|-----------------------------|----------------------------|
| **Perspective** | â€œA health system perspective was adopted, including only direct medical costs as per MaHTAS guidelines.â€ | â€œCosts were included.â€ |
| **Discount Rate** | â€œBoth costs and QALYs were discounted at 3% annually, consistent with WHO guidelines.â€ | â€œDiscounting was applied.â€ |
| **Health Outcomes** | â€œQALYs were estimated using EQ-5D-5L with Malaysian value set.â€ | â€œQALYs were used.â€ |
| **Resource Use & Costs** | â€œResource use was obtained from clinical records, and unit costs were sourced from MOH tariffs.â€ | â€œCosts were estimated.â€ |
| **Analytical Methods** | â€œA Markov model with 1-year cycles simulated transitions between health states.â€ | â€œA model was used to project results.â€ |
| **Sensitivity Analysis** | â€œOne-way and probabilistic sensitivity analyses were conducted on drug cost, utilities, and transition probabilities.â€ | â€œSensitivity analysis was done.â€ |
- **Question for Appraisal**: *Could a policymaker or researcher reproduce this study based on whatâ€™s reported in the methods section?*

### ğŸ“Š Selected CHEERS Items (From Slides)

- **3. Background & Objectives**: 
  - *Give the context for the study, the study question, and its practical relevance for decision-making in policy or practice.*
- **4. Health Economic Analysis Plan**: 
  - *Indicate whether a health economic analysis plan was developed and where available.*
- **5. Study Population**: 
  - *Describe characteristics of the study population (such as age range, demographics, socioeconomic, or clinical characteristics).*
- **6. Setting & Location**: 
  - *Provide relevant contextual information that may influence findings.*
- **7. Comparators**: 
  - *Describe the interventions or strategies being compared and why chosen.*
- **8. Perspective**: 
  - *State the perspective(s) adopted by the study and why chosen.*
- **9. Time Horizon**: 
  - *State the time horizon for the study and why appropriate.*
- **10. Discount Rate**: 
  - *Report the discount rate(s) and reason chosen.*
- **11. Selection of Outcomes**: 
  - *Describe what outcomes were used as the measure(s) of benefit(s) and harm(s).*
- **12. Measurement of Outcomes**: 
  - *Describe how outcomes used to capture benefit(s) and harm(s).*
- **18. Characterizing Heterogeneity**: 
  - *Describe any methods used for estimating how the results of the study vary for sub-groups.*
- **19. Characterizing Distributional Effects**: 
  - *Describe how impacts are distributed across different individuals or adjustments made to reflect priority populations.*
- **20. Characterizing Uncertainty**: 
  - *Describe methods to characterize any sources of uncertainty in the analysis.*
- **21. Approach to Engagement with Patients and Others**: 
  - *Describe any approaches to engage patients or service recipients, the general public, communities, or stakeholders (e.g., clinicians or payers) in the design of the study.*
- **25. Effect of Engagement with Patients and Others**: 
  - *Describe the impact of engagement with patients or stakeholders on the study.*

---

## ğŸ” 6. Applying the CHEERS Checklist

### ğŸ“– How to Use CHEERS

- **Process**:
  1. **Read the Article**: Review section by section (**Title/Abstract**, **Introduction**, **Methods**, **Results**, **Discussion**).
  2. **Match to CHEERS Items**: Align each section with the relevant **28 checklist items** across **6 domains**.
  3. **Evaluate Reporting**:
     - Was the item **clearly and fully reported**?
     - Was it **mentioned but unclear/incomplete**?
     - Was it **missing altogether**?
- **Goal**: Assess **clarity**, **transparency**, and **reproducibility** of the study.

### ğŸŒŸ Importance

- Ensures **decision-makers** (e.g., MaHTAS, policymakers) can **trust** and **use** the evaluation.
- Enhances **policy impact** by making methods and assumptions **visible**.

---

## ğŸ“Š 7. Case Study: Lung Cancer Screening in Germany

### ğŸ“– Study Overview

- **Title**: *Cost-utility analysis of a potential lung cancer screening program for a high-risk population in Germany: A modelling approach*
- **Authors**: Florian Hofer, Hans-Ulrich Kauczor, Tom Stargardt
- **Source**: Not fully provided in slides (incomplete due to truncation).

### ğŸ“‹ Article Information

- **Keywords**: Early detection, LDCT screening, health economic evaluation, cost-effectiveness analysis, Markov modeling, Bayesian calibration.
- **Background**: Lung cancer is the **leading cause of cancer death** in Germany. While randomized trials have evaluated **effectiveness** of screening, **cost-effectiveness** evidence is scarce.
- **Objective**: Evaluate the **cost-effectiveness** of a population-based **lung cancer screening program** from a **public payer perspective** for a **high-risk population** (heavy smokers, â‰¥20 cigarettes/day, aged 55â€“75).
- **Methods**:
  - **Model**: Two **Markov models** comparing:
    - **Annual screening program** vs. **standard clinical care**.
  - **Population**: High-risk smokers (â‰¥20 cigarettes/day, aged 55â€“75).
  - **Treatment Paths**: Five paths based on **stage at diagnosis**, per German clinical guidelines.
  - **Outcomes**: **Costs**, **life years saved**, **QALYs**.
  - **Data Sources**: Literature-based input parameters.
  - **Time Horizon**: 60 cycles (3-month cycle length).
  - **Analyses**: **Deterministic** and **probabilistic sensitivity analyses**.
- **Results**:
  - **Base Case**: Annual screening increased **incremental costs** (â‚¬1,153 per person) but gained **0.06 life years** and **0.04 QALYs** per person.
  - **ICER**: Not fully provided in slides (truncated text: â€œâ‚¬1,3, 3, 3, â€¦â€), but implied to be calculated as cost per QALY.

---

## ğŸš« 8. Common Reporting Gaps in Economic Evaluations

### ğŸ“– Overview

Incomplete or inconsistent reporting undermines the **credibility** and **usability** of economic evaluations. The **top 5 reporting gaps** identified in the lecture are critical to address for **policy-relevant** studies.

1. **Perspective Not Stated**:
   - **Issue**: Many studies fail to clarify whether the analysis uses a **societal**, **payer**, or **provider** perspective.
   - **Why It Matters**: Perspective determines **which costs** and **outcomes** should be included.
   - **Example**: A study includes only **drug costs** but claims **societal relevance**, misleading stakeholders.

2. **No Justification for Time Horizon or Discount Rate**:
   - **Issue**: Time horizons are sometimes chosen **randomly**, and **discounting** may be applied without explanation or omitted.
   - **Why It Matters**: 
     - Short timeframes can **misrepresent** chronic disease costs/benefits.
     - Discounting ensures **future costs/outcomes** are weighted appropriately.
   - **Example**: Modeling **lifetime outcomes** without reporting **discounting**.

3. **Omission of Sensitivity Analysis**:
   - **Issue**: Studies may lack **sensitivity analysis** or test only **trivial variables**.
   - **Why It Matters**: Sensitivity analysis tests **robustness** under uncertainty, critical for **policy confidence**.
   - **Example**: Not testing variations in **utility scores** for high-impact side effects.

4. **Incomplete Model Structure Explanation**:
   - **Issue**: Models (e.g., Markov) are used without detailing **structure**, **assumptions**, or **parameters** (e.g., transition probabilities).
   - **Why It Matters**: Without clarity, models are **opaque** and **non-reproducible**.
   - **Example**: Stating â€œa model was usedâ€ without specifying **health states** or **cycle length**.

5. **Utility Sources Not Reported**:
   - **Issue**: Studies state **QALYs** were calculated but omit details on:
     - **Instruments** used (e.g., EQ-5D, SF-6D).
     - **Population** or **country-specific value sets**.
   - **Why It Matters**: **Utility weights** vary by setting and impact **QALY estimates**.
   - **Example**: Stating â€œutility weights from the literatureâ€ without citation.

---

## ğŸŒŸ 9. Why Reporting Quality Equals Policy Impact

### ğŸ“– Importance

- **Economic evaluations** inform critical decisions in:
  - **Health Technology Assessments (HTA)**.
  - **Budget impact analysis** and **resource allocation**.
  - **Reimbursement decisions** and **coverage recommendations**.
  - **National clinical guidelines** and **service prioritization**.
- **Impact of Poor Reporting**: Unclear studies cannot be used by **policymakers**, regardless of result validity, reducing their **policy impact**.

### ğŸ“‹ Key Takeaways
- **CHEERS 2022** enhances **clarity**, **transparency**, and **policy usability** of economic evaluations.
- **Appraising with CHEERS**:
  - Helps assess **what was done** and **how clearly it was communicated**.
  - Is distinct from **technical peer review** but equally essential.
- **Common Gaps**:
  - Missing **perspective**, **discounting**, and **sensitivity analyses**.
  - Poor explanation of **models** and **QALY derivation**.
- **Transparent Reporting**: Builds **trust** and increases **policy uptake**.

---
