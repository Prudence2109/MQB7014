# HE 12 - Economic Evaluation IV: Applying Economic Evaluation in Policy and Practice 

**Prepared by: Dr Ainol Haniza Kherul Anuwar**  
**DDS (UGM), MCOH (Distinction) (Malaya), DrDPH (Malaya)**  
**Department of Community Oral Health & Clinical Prevention, Faculty of Dentistry, Universiti Malaya**  
**Credit: Prof Dr Maznah Dahlui, Department of Social & Preventive Medicine, Faculty of Medicine, Universiti Malaya**  
**Lecture Date: June 19, 2025**

---

## Executive Summary üìö

**Economic Evaluation IV: Applying Economic Evaluation in Policy and Practice** marks the culminating lecture of the Health Economics module, shifting the focus from theoretical and methodological foundations to the **practical application** of economic evaluations (EEs) in shaping health policy. This session equips students with the skills to translate EE results into actionable policy recommendations, navigating the complexities of financial, ethical, and operational constraints. By emphasizing key concepts like **Incremental Cost-Effectiveness Ratios (ICERs)**, **Diagnosis-Related Group (DRG)/case-mix costing**, **Willingness-to-Pay (WTP)**, and **Multi-Criteria Decision Analysis (MCDA)**, the lecture prepares future health leaders to influence resource allocation, access, and system evolution in contexts like Malaysia‚Äôs public healthcare system. Below is a concise summary of the lecture‚Äôs key points, learning outcomes, and critical terminologies, designed to provide a clear overview for policymakers, students, and stakeholders.

### Key Learning Outcomes üéØ

The lecture outlines four core competencies essential for applying EEs in policy:

- **Interpret ICERs**: Understand and evaluate ICERs against WTP thresholds and budget impacts to assess cost-effectiveness and affordability.
- **Explain DRG/Case-Mix Costing**: Describe its role in standardizing costs for national health financing and Health Technology Assessments (HTAs).
- **Compare WTP Thresholds**: Analyze GDP-based and stated preference methods (e.g., Contingent Valuation, Discrete Choice Experiments) to understand societal valuation of health gains.
- **Apply EE Results**: Use structured exercises to simulate policy decisions, balancing cost-effectiveness, equity, and feasibility.

**Why It Matters**: These outcomes enable students to move beyond academic analysis, using EEs to address real-world challenges, such as optimizing Malaysia‚Äôs Universal Health Coverage (UHC) framework while ensuring equitable access.

### Lecture Progression and Context üöÄ

Lecture IV builds on the preceding sessions in the Economic Evaluation series:

|**Lecture**|**Focus**|**Key Topics**|
|---|---|---|
|**EE I**|Overview|Types of EE (CEA, CUA, CBA), key steps (perspective, costs/outcomes)|
|**EE II**|Conducting EE|Costing (micro-costing, DRG), outcomes (QALYs/DALYs), modeling (decision trees, Markov models)|
|**EE III**|Appraising EE|CHEERS 2022 checklist, identifying gaps (e.g., missing perspective, weak sensitivity analysis)|
|**EE IV**|Applying EE|ICER interpretation, WTP, DRG, MCDA, policy relevance|

**Lecture IV** emphasizes **practical application**, teaching students to use EE tools strategically in the ‚Äúmessy, complex world of policy,‚Äù addressing trade-offs like affordability, equity, and system readiness.

### Core Concepts and Insights üåü

The lecture covers several critical areas, each reinforced through practical examples and frameworks:

#### ICERs and Cost-Effectiveness üìä

- **Definition**: The **Incremental Cost-Effectiveness Ratio (ICER)** measures the additional cost per additional unit of health outcome (e.g., QALY gained):  
    $$\text{ICER} = \frac{\text{Cost}_{\text{new}} - \text{Cost}_{\text{comparator}}}{\text{Effect}_{\text{new}} - \text{Effect}_{\text{comparator}}}$$
- **Insight**: A low ICER is a **good start but not the finish line**. Policy decisions require balancing cost-effectiveness with **budget impact**, **equity**, **clinical context**, and **system readiness**.

#### WTP Thresholds üìè

- **Definition**: The **Willingness-to-Pay (WTP)** threshold is the maximum amount a health system or society is willing to pay for a unit of health gain (e.g., QALY or DALY averted).
- **Sources**: Include 1‚Äì3√ó GDP per capita (e.g., Malaysia: RM 48,000‚Äì144,000), WTP studies (Contingent Valuation, Discrete Choice Experiments), historical benchmarks, and deliberative processes.
- **Caution**: Thresholds are **not universal or static**, and a favorable ICER does not guarantee approval due to budget, feasibility, or ethical constraints.

#### DRG/Case-Mix Costing üè•

- **Definition**: **Diagnosis-Related Group (DRG)/case-mix costing** classifies patients into clinically similar groups with similar resource use, using cost weights and a base rate:  
    $$\text{BR}_t = \frac{\text{HP}_t}{\text{Cases}_{h,t-1}}$$
- **Application**: Used in Malaysia‚Äôs MOH and university hospitals for budgeting, reimbursement, and MaHTAS evaluations, though limited by irregular IT infrastructure and data dependency.
- **Insight**: DRG offers **scalability**, while **micro-costing** provides precision, with good EEs choosing the appropriate method based on context.

#### Budget Impact vs. Cost-Effectiveness üí∏

- **Insight**: A low ICER does not ensure affordability. **Budget impact** assesses total costs at scale, highlighting trade-offs like **fiscal space**, **opportunity cost**, and **feasibility**.
- **Example**: An intervention with an ICER of RM 95,000 for 1.5 million people costs RM 142.5 million, potentially straining budgets despite cost-effectiveness.

#### Ethical and Equity Considerations ‚öñÔ∏è

- **Dilemma**: Balancing **efficiency** (maximizing health gains) with **equity** (fair access for vulnerable groups).
- **Scenarios**: Policymakers may prioritize high-ICER interventions for **end-of-life care**, **rare diseases**, **marginalized populations**, or **childhood interventions** due to societal values.

#### Multi-Criteria Decision Analysis (MCDA) üß†

- **Definition**: **MCDA** combines evidence with values, scoring criteria like cost-effectiveness, equity, and feasibility to inform decisions.
- **Example**: HPV self-sampling scores high in MCDA due to strong ICER, equity benefits, and feasibility, unlike diabetes screening, which is limited by high budget impact.
- **Insight**: MCDA ensures **transparent, balanced decisions**, integrating evidence, ethics, and economics.

#### Policy-Relevant EEs üìú

- **Features**: Must be **timely**, **context-specific** (using local data like Malaysian EQ-5D tariffs), **actionable**, and aligned with policy mandates.
- **Contrast**: Unlike academic EEs, which focus on methodological novelty, policy-relevant EEs address urgent questions and include budget impact.

### Key Terminologies Introduced üìò

The lecture introduces several critical terms, essential for understanding and applying economic evaluations in policy:

- **Incremental Cost-Effectiveness Ratio (ICER)**: The additional cost per additional unit of health outcome (e.g., QALY), calculated as:  
    $$\text{ICER} = \frac{\text{Cost}_{\text{new}} - \text{Cost}_{\text{comparator}}}{\text{Effect}_{\text{new}} - \text{Effect}_{\text{comparator}}}$$
- **Willingness-to-Pay (WTP)**: The maximum amount society is willing to pay for a health gain, used as a threshold for ICERs.
- **Diagnosis-Related Group (DRG)/Case-Mix Costing**: A method to classify patients into groups with similar resource use, with costs calculated using a base rate:  
    $$\text{BR}_t = \frac{\text{HP}_t}{\text{Cases}_{h,t-1}}$$
- **Quality-Adjusted Life Year (QALY)**: A measure of health outcome combining quality and quantity of life.
- **Disability-Adjusted Life Year (DALY)**: A measure of disease burden, reflecting years lost due to disability or premature death.
- **Budget Impact**: The total cost of implementing an intervention across a population, assessing affordability.
- **Fiscal Space**: A government‚Äôs capacity to fund interventions without jeopardizing (jeopardizing) financial stability.
- **Multi-Criteria Decision Analysis (MCDA)**: A framework to combine evidence, values, and constraints for decision-making.
- **Contingent Valuation (CV)**: A survey method directly asking individuals their WTP for health outcomes.
- **Discrete Choice Experiment (DCE)**: A survey method presenting hypothetical options to infer WTP through trade-offs.
- **Health Technology Assessment (HTA)**: A systematic evaluation of health interventions, often using ICERs and WTP.
- **MaHTAS**: Malaysian Health Technology Assessment Section, supporting EE for policy decisions.
- **UNU-CBG Grouper**: A tool for generating DRG codes in Malaysia‚Äôs casemix system.
- **Equity**: Fair distribution of health resources, prioritizing vulnerable or marginalized groups.

### Key Takeaways for Future Health Leaders üåü

- **ICER ‚â† Final Answer**: Context, budget, equity, and feasibility are critical for policy decisions.
- **DRG Scalability**: Supports national financing and HTAs, though limited by data and IT challenges.
- **WTP Flexibility**: Public preferences enhance threshold relevance beyond GDP-based metrics.
- **Policy Impact**: EEs must be timely, context-specific, and actionable to shape access and system evolution.
- **Holistic Decisions**: MCDA integrates evidence, ethics, and economics for transparent, balanced policies.

**Conclusion**: Economic Evaluation IV empowers students to apply EEs strategically, addressing real-world policy challenges in Malaysia and beyond. By mastering ICERs, WTP, DRG, and MCDA, future health leaders can drive equitable, efficient, and sustainable health systems, ensuring that evaluations translate into meaningful action rather than remaining in reports.

---

## 1. Introduction to Economic Evaluation IV üìö

Economic Evaluation IV bridges the gap between theoretical economic evaluation (EE) and its practical application in shaping health policy and practice. This session builds on the foundational knowledge, methodological skills, and appraisal techniques covered in Lectures I‚ÄìIII, shifting the focus to **real-world decision-making**. By emphasizing **Incremental Cost-Effectiveness Ratios (ICERs)**, **Diagnosis-Related Group (DRG)/case-mix costing**, and **Willingness-to-Pay (WTP)** analysis, this lecture equips students with the tools to navigate the complexities of policy environments where financial, ethical, and operational constraints intersect.

**Key Focus**: The lecture explores how to use EE results to inform **health policy decisions**, ensuring that interventions are not only cost-effective but also feasible, equitable, and aligned with societal values. It underscores the importance of translating numerical outputs, such as ICERs, into actionable recommendations that address the "messy, complex world of policy."

### Learning Outcomes üéØ

By the end of this session, students will be equipped with the following competencies, which are critical for health policy analysis and decision-making:

1. **Interpret ICERs** in the context of WTP thresholds and budget impact.
    
    - Understand how ICERs quantify the cost-effectiveness of interventions.
    - Evaluate ICERs against WTP thresholds to determine whether an intervention is worth funding.
    - Consider budget constraints to assess affordability at scale.
2. **Explain the role of case-mix/DRG costing** in national-level health financing and economic evaluations.
    
    - Describe how DRG systems standardize costing for clinically similar patient groups.
    - Highlight the use of DRG in hospital reimbursement, budgeting, and health technology assessments (HTAs).
    - Recognize the scalability of DRG costing for national health financing strategies.
3. **Compare different WTP thresholds**, including GDP-based and stated preference methods.
    
    - Differentiate between threshold derivation methods, such as WHO-CHOICE GDP-based thresholds and survey-based approaches like contingent valuation (CV) and discrete choice experiments (DCE).
    - Analyze the strengths and limitations of each method in reflecting societal preferences.
4. **Apply EE results** using structured exercises to simulate policy decision-making.
    
    - Engage in practical exercises to evaluate interventions based on ICERs, budget impact, and feasibility.
    - Develop rationales for funding decisions, considering trade-offs like equity, urgency, and system readiness.

**Why These Outcomes Matter**: These skills enable future health leaders to move beyond academic analysis, using EE as a tool to shape policies that improve access, optimize resource allocation, and address health inequities. The focus on practical application ensures that students can contribute meaningfully to Malaysia‚Äôs health system and beyond.

---

## 2. Course Progression: Where We Are üöÄ

The series is structured to build skills incrementally, with each lecture focusing on a distinct aspect of economic evaluation. The following table summarizes the progression, highlighting the focus and key topics of each lecture to contextualize where Lecture IV fits in the learning journey:

|**Lecture**|**Focus**|**Key Topics**|
|---|---|---|
|**EE I**|Overview|Foundations, types of EE (CEA, CUA, CBA), key terms|
|**EE II**|Conducting EE|Steps in EE, costing, outcomes, modeling|
|**EE III**|Appraising EE|CHEERS 2022 checklist, transparent reporting|
|**EE IV**|Applying EE|ICER interpretation, WTP, DRG, policy relevance|

### Understanding the Progression üìö

- **EE I: Overview** lays the groundwork by introducing the **foundations of economic evaluation**. It covers the types of EE‚Äî**Cost-Effectiveness Analysis (CEA)**, **Cost-Utility Analysis (CUA)**, and **Cost-Benefit Analysis (CBA)**‚Äîand defines key terms essential for understanding health economics. This lecture establishes the theoretical framework that underpins the subsequent sessions.
- **EE II: Conducting EE** dives into the practical steps of performing an economic evaluation. It focuses on **costing methods**, **outcome measurement**, and **modeling techniques**, such as decision trees and Markov models, enabling students to design and execute robust EEs.
- **EE III: Appraising EE** emphasizes the importance of **quality and transparency** in EE studies. It introduces the **CHEERS 2022 checklist**, a standardized tool for evaluating the reporting quality of EEs, ensuring students can critically assess published studies for reliability and relevance.
- **EE IV: Applying EE**‚Äîthe focus of this lecture‚Äîsynthesizes the skills from the previous sessions and applies them to **policy and practice**. It explores how to interpret **Incremental Cost-Effectiveness Ratios (ICERs)**, leverage **Diagnosis-Related Group (DRG)/case-mix costing**, and use **Willingness-to-Pay (WTP)** analysis to make informed policy decisions. This lecture addresses the complexities of real-world application, where decisions must account for budget constraints, ethical considerations, and system readiness.

### Why Lecture IV Matters üåü

**Lecture IV** represents a pivotal shift from technical skills to **practical application**. While the earlier lectures focus on understanding, designing, and critiquing EEs, this session challenges students to use these tools in the "messy, complex world of policy." It emphasizes:

- **Real-World Relevance**: Policy decisions often involve trade-offs that go beyond numerical outputs, requiring a nuanced understanding of context, stakeholder priorities, and societal values.
- **Decision-Making Skills**: Students learn to translate EE results into actionable recommendations, considering factors like affordability, feasibility, and equity.
- **Policy Impact**: By focusing on ICER interpretation, DRG costing, and WTP analysis, Lecture IV prepares students to influence health systems, ensuring resources are allocated efficiently and equitably.

**Key Insight**: Lecture IV is not about learning new techniques but about **using existing tools strategically** to address policy challenges. It equips students to bridge the gap between academic analysis and practical impact, making it a cornerstone of the Health Economics module.

---

## 3. From Numbers to Decisions: Understanding ICERs üìä

The **Incremental Cost-Effectiveness Ratio (ICER)** serves as a cornerstone of economic evaluation, providing a critical metric to compare the value of health interventions. However, a low ICER alone is not sufficient for policy approval, as real-world health policy decisions demand a broader perspective that accounts for financial, ethical, and practical considerations. This section delves into the definition, calculation, and interpretation of ICERs, while highlighting why a favorable ICER is only the starting point in the complex landscape of health policy decision-making.

### What is an ICER? üßÆ

The ICER quantifies the **additional cost per additional unit of health outcome** when comparing two interventions, offering a standardized way to assess the cost-effectiveness of a new intervention relative to a comparator (e.g., standard care). It is expressed mathematically as:

$$\text{ICER} = \frac{\text{Cost}_{\text{new}} - \text{Cost}_{\text{comparator}}}{\text{Effect}_{\text{new}} - \text{Effect}_{\text{comparator}}}$$

- **Interpretation**: The ICER represents the **extra cost per extra unit of outcome**, such as per **Quality-Adjusted Life Year (QALY)** gained. A lower ICER indicates better cost-effectiveness, as it suggests that the additional health benefits are achieved at a relatively lower cost.
- **Example**: If a new treatment costs RM 10,000 more than the comparator and yields 0.5 additional QALYs, the ICER is calculated as:

$$\text{ICER} = \frac{10000}{0.5} = 20000 \text{ RM per QALY}$$

This means the new treatment costs **RM 20,000 per additional QALY gained**. To determine if this is cost-effective, the ICER must be compared to a **Willingness-to-Pay (WTP)** threshold, which reflects the maximum amount a health system or society is willing to pay for a unit of health gain.

**Why It Matters**: The ICER provides a clear, quantifiable metric to guide resource allocation decisions, helping policymakers prioritize interventions that deliver the most health benefits for the available budget. However, its utility depends on contextual factors, such as the threshold used and the broader policy environment.

### Why a Good ICER Isn‚Äôt Enough? üö´

While a low ICER indicates that an intervention is cost-effective on a per-patient basis, it does not guarantee policy approval. **Policy decisions require consideration of additional factors** that go beyond the mathematical elegance of the ICER. These factors ensure that interventions are not only cost-effective but also feasible, equitable, and aligned with the health system‚Äôs capacity and societal values. The following table outlines these critical considerations:

|**Factor**|**Explanation**|
|---|---|
|**Willingness-to-Pay (WTP)** üéØ|Is the ICER below the country‚Äôs cost-effectiveness threshold? For example, if Malaysia‚Äôs WTP threshold is RM 120,000 per QALY, an ICER of RM 20,000 is favorable, but an ICER of RM 150,000 may be deemed too costly.|
|**Budget Impact** üí∞|Can the intervention be afforded at scale, even if cost-effective per patient? A low ICER for a treatment may still result in unsustainable costs if applied to a large population.|
|**Equity & Ethics** ‚öñÔ∏è|Who benefits? Are vulnerable or marginalized groups reached? Interventions that prioritize underserved populations may be favored, even if their ICERs are higher.|
|**Clinical Context** üìà|Is the health benefit significant enough to matter in practice? A statistically significant QALY gain may be clinically negligible, reducing its policy relevance.|
|**System Readiness** üè•|Can the health system feasibly implement the intervention? Factors like infrastructure, trained staff, and supply chains must be in place for successful adoption.|

The ICER is a powerful tool for comparing interventions, but its limitations become apparent in policy contexts where resources are finite and priorities compete. For instance, an intervention with a low ICER may be unaffordable if it requires significant upfront investments or if it diverts funds from other critical services (opportunity cost). Similarly, ethical considerations, such as ensuring access for rural or low-income populations, may outweigh a slightly higher ICER. The health system‚Äôs capacity to deliver the intervention‚Äîsuch as the availability of specialized equipment or trained personnel‚Äîfurther complicates decisions. Thus, while the ICER provides a starting point, it must be interpreted within a broader framework that accounts for these real-world constraints.

**Key Takeaway**: A low ICER is a **good start but not the finish line**. Policy decisions require more than just mathematics, as they must balance cost-effectiveness with affordability, fairness, clinical relevance, and practical feasibility. This holistic approach ensures that health policies maximize societal benefit while addressing the diverse needs of the population.

---

## 4. Cost-Effectiveness Thresholds: Judging ICERs üìè

A **cost-effectiveness threshold** is a pivotal concept in health economics, defining the **maximum amount a health system or society is willing to pay** for one unit of health gain, such as one **Quality-Adjusted Life Year (QALY)** gained or one **Disability-Adjusted Life Year (DALY)** averted. This threshold serves as a benchmark for evaluating the **Incremental Cost-Effectiveness Ratio (ICER)** of an intervention, guiding policymakers in determining whether an intervention represents good value for money. This section explores how cost-effectiveness is determined, the sources of WTP thresholds, and critical cautions to consider when applying these thresholds in policy decisions, ensuring that students understand both the mechanics and the nuanced challenges of using thresholds in practice.

### How is Cost-Effectiveness Determined? ‚úÖ

An intervention is deemed **cost-effective** if its ICER is **below the WTP threshold**, indicating that the additional cost per unit of health gain is within what the health system or society is willing to pay. The ICER, calculated as:

$$\text{ICER} = \frac{\text{Cost}_{\text{new}} - \text{Cost}_{\text{comparator}}}{\text{Effect}_{\text{new}} - \text{Effect}_{\text{comparator}}}$$

is compared against the WTP threshold to make funding decisions. The following table illustrates this process with examples:

|**ICER (RM per QALY)**|**WTP Threshold (RM per QALY)**|**Decision**|
|---|---|---|
|60,000|120,000|‚úÖ Cost-effective|
|150,000|120,000|‚ùå Not cost-effective|

In the first example, an ICER of RM 60,000 per QALY is well below the WTP threshold of RM 120,000, suggesting that the intervention is a cost-effective use of resources. Conversely, an ICER of RM 150,000 exceeds the threshold, indicating that the intervention is not cost-effective unless other factors (e.g., equity or unmet need) justify its funding. This comparison is central to **Health Technology Assessments (HTAs)**, where policymakers use thresholds to prioritize interventions that maximize health benefits within budget constraints. However, the threshold‚Äôs value and its application can vary significantly, influenced by economic, social, and political contexts.

### Sources of WTP Thresholds üåê

Thresholds vary by country and are derived from multiple methods, each with its own strengths and limitations. Understanding these sources is crucial for interpreting ICERs in context and appreciating the diversity of approaches to setting thresholds. The following table summarizes the primary methods:

|**Method**|**Explanation**|
|---|---|
|**1‚Äì3√ó GDP per capita**|Early WHO-CHOICE guidance (e.g., Malaysia: RM 48,000‚Äì144,000). This method ties thresholds to a country‚Äôs economic capacity, assuming that health systems can afford to pay one to three times the per capita GDP for a QALY or DALY averted.|
|**WTP Studies (CV/DCE)**|Surveys of how much individuals or society would pay for a QALY, using methods like **Contingent Valuation (CV)** or **Discrete Choice Experiments (DCE)**. These capture societal preferences but may be influenced by survey design and respondent biases.|
|**Historical Benchmarks**|Based on past funding decisions (revealed preferences). This method reflects actual spending patterns but may perpetuate existing inequities or inefficiencies.|
|**Deliberative Process**|HTA panels or policy consensus (e.g., Thailand‚Äôs HTA committee). This involves expert and stakeholder input to set thresholds, balancing evidence with societal values and policy goals.|

The **1‚Äì3√ó GDP per capita** method, rooted in WHO-CHOICE guidance, provides a simple, economically grounded benchmark, particularly useful for low- and middle-income countries like Malaysia, where thresholds might range from RM 48,000 to RM 144,000 based on GDP. However, this approach may not fully capture societal preferences or health system priorities. **WTP studies**, such as CV and DCE, offer a more nuanced view by directly surveying individuals, but their results can vary depending on how questions are framed or who is surveyed. **Historical benchmarks** provide practical insight into what a health system has been willing to pay, but they may not align with current priorities. **Deliberative processes**, like those used in Thailand, integrate evidence and stakeholder perspectives, making them context-specific but resource-intensive. Each method contributes to a richer understanding of cost-effectiveness, but their variability underscores the need for careful interpretation.

### Cautions ‚ö†Ô∏è

Applying cost-effectiveness thresholds requires caution, as their use is fraught with complexities that can impact policy decisions. The following points highlight key considerations:

- **Thresholds are not universal or static**: They vary by country, context, and time. For example, a threshold suitable for Malaysia may not apply to a wealthier nation, and economic changes can shift thresholds over time.
- A **favorable ICER** does not guarantee policy approval due to:
    - **Budget impact**: Total cost at scale may be unaffordable, even if the ICER is low. For instance, a cost-effective intervention for a large population could strain national budgets.
    - **Feasibility**: Implementation challenges, such as inadequate infrastructure or trained personnel, may limit adoption, regardless of cost-effectiveness.
    - **Ethical implications**: Equity and fairness considerations may override cost-effectiveness. For example, interventions targeting marginalized groups might be prioritized despite higher ICERs to address health disparities.
- **Key Insight**: Thresholds provide a reference point, but real decisions require **context, judgment, and constraints**. Policymakers must weigh cost-effectiveness against practical realities and societal values to ensure equitable and sustainable health policies.

The variability of thresholds highlights their role as **guidelines rather than rigid rules**. For instance, a low ICER may not lead to funding if the intervention‚Äôs total cost exceeds the health system‚Äôs fiscal space, forcing policymakers to consider opportunity costs (e.g., what other services might be sacrificed). Similarly, **feasibility** issues, such as the need for specialized equipment or extensive training, can render a cost-effective intervention impractical. **Ethical considerations**, such as prioritizing rare diseases or end-of-life care, may lead to exceptions where higher ICERs are accepted to meet societal or moral imperatives. This nuanced approach ensures that thresholds are applied thoughtfully, balancing economic rigor with the realities of health system capacity and societal priorities.

---

## 5. Exercise: Which Intervention is Worth Funding? üßë‚Äç‚öñÔ∏è

This exercise immerses students in a realistic **policy decision-making scenario**, challenging them to advise the Ministry of Health on which of three interventions to fund, based on economic evaluation data. With a **Willingness-to-Pay (WTP) threshold** of RM 120,000 per Quality-Adjusted Life Year (QALY), students must weigh the **Incremental Cost-Effectiveness Ratios (ICERs)** alongside other critical factors such as budget impact, feasibility, and equity. The exercise underscores the complexity of health policy decisions, where cost-effectiveness is just one piece of a multifaceted puzzle. By engaging with this scenario, students learn to apply economic evaluation principles practically, developing the rationale needed to justify funding decisions in the "messy, complex world of policy."

### Intervention Data üìä

The exercise provides data from three recent economic evaluations, detailing the ICER, budget impact, target population, and feasibility notes for each intervention. The following table summarizes the key information:

|**Intervention**|**ICER (RM per QALY)**|**Total Budget Impact (Annual)**|**Target Population Size**|**Feasibility Notes**|
|---|---|---|---|---|
|**A: HPV Self-Sampling**|85,000|RM 50 million|500,000 women|Mobile deployment required|
|**B: Stroke Rehabilitation**|130,000|RM 15 million|80,000 patients|Implemented in select rehab centers|
|**C: Type 2 DM Screening**|95,000|RM 200 million|1.5 million adults|High staff training and IT cost upfront|

The data presents a diverse set of interventions, each targeting different health challenges and populations. **HPV self-sampling** aims to improve cervical cancer screening among women, with a moderate ICER and budget impact but requiring mobile infrastructure. **Stroke rehabilitation** focuses on a smaller, specialized population, with a higher ICER but lower budget impact, leveraging existing rehab centers. **Type 2 diabetes screening** addresses a large population with significant public health implications, but its high budget impact and upfront costs pose challenges. This diversity forces students to consider not only cost-effectiveness but also the scale, feasibility, and societal impact of each intervention, mirroring real-world policy dilemmas.

### Discussion Questions ‚ùì

To guide the decision-making process, the exercise poses five critical questions that encourage students to analyze the data holistically and justify their recommendations:

1. **Which ICERs are below the WTP threshold?**
    - Students must identify which interventions have ICERs less than RM 120,000 per QALY, indicating cost-effectiveness.
2. **Which intervention has the most favorable ICER?**
    - This requires comparing ICERs to determine which intervention offers the best value for money relative to the threshold.
3. **Does budget impact change your recommendation?**
    - Students must assess whether the total cost of implementing an intervention at scale affects its viability, even if it is cost-effective.
4. **What if equity is a policy priority?**
    - This question prompts consideration of whether interventions targeting underserved or vulnerable groups (e.g., women, rural populations) should be prioritized.
5. **What if the program must be implemented within 12 months?**
    - Students must evaluate feasibility constraints, such as the time required for infrastructure development or training.

These questions are designed to push students beyond a simplistic ICER comparison, encouraging them to grapple with **trade-offs**. For example, an intervention with a low ICER might be unaffordable due to high budget impact, or a feasible intervention might not align with equity goals. The question about a 12-month implementation timeline highlights the urgency often faced in policy contexts, where delays can undermine public health goals. By addressing these questions, students develop a nuanced understanding of how economic evaluations inform, but do not dictate, policy decisions.

### Key Insights from the Exercise üåü

The exercise yields several critical insights that reinforce the practical application of economic evaluation in policy-making:

- **No right or wrong answer**: The rationale behind the decision is critical. The exercise emphasizes that the strength of a recommendation lies in its justification, which must account for multiple dimensions of value.
- **Contextual trade-offs** include:
    - **Affordability**: Can the budget support the intervention at scale? For instance, Type 2 DM screening‚Äôs RM 200 million annual cost may strain resources despite its favorable ICER.
    - **Scale**: How many people will benefit? HPV self-sampling and Type 2 DM screening target large populations, while stroke rehabilitation serves a smaller group.
    - **Feasibility**: Is the infrastructure ready? Mobile deployment for HPV self-sampling or IT upgrades for diabetes screening may pose logistical challenges.
    - **Urgency**: Can it be implemented quickly? Stroke rehabilitation, using existing centers, may be faster to roll out than interventions requiring new systems.
    - **Equity**: Does it address underserved populations? HPV self-sampling may prioritize women‚Äôs health, potentially addressing gender-based health disparities.
- **Conclusion**: Even if interventions are cost-effective, policy decisions require **value judgments** based on multiple criteria. This highlights the need for a balanced approach that integrates economic evidence with ethical, practical, and societal considerations.

The insight that there is **no right or wrong answer** underscores the subjective nature of policy decisions, where different stakeholders may prioritize different criteria (e.g., cost vs. equity). The listed trade-offs reflect real-world complexities: **affordability** ensures fiscal sustainability, **scale** determines public health impact, **feasibility** addresses system capacity, **urgency** aligns with policy timelines, and **equity** ensures fairness. For example, a policymaker might favor HPV self-sampling for its moderate cost and equity benefits, while another might choose stroke rehabilitation for its lower budget impact and faster implementation. The exercise teaches students to articulate these trade-offs clearly, preparing them to navigate stakeholder negotiations and defend their recommendations with robust evidence.

---

## 6. Budget Impact vs. Cost-Effectiveness üí∏

While a low **Incremental Cost-Effectiveness Ratio (ICER)** signals that an intervention is cost-effective on a per-patient basis, it does not guarantee **affordability** when scaled across a population. **Budget impact** assesses the **total cost** of implementing an intervention for the target population, revealing whether a health system can sustain the financial burden. This section explores the distinction between cost-effectiveness and budget impact, using examples to illustrate their interplay, and highlights the policy trade-offs that policymakers must navigate to ensure interventions are both valuable and feasible. By understanding these concepts, students can better appreciate the fiscal realities that shape health policy decisions.

### Example Comparison üìä

To illustrate the difference between cost-effectiveness and budget impact, consider two hypothetical interventions, both evaluated against a **Willingness-to-Pay (WTP) threshold** of RM 120,000 per Quality-Adjusted Life Year (QALY). The following table compares their ICERs, population sizes, and total costs:

|**ICER (RM per QALY)**|**Total Population Impacted**|**Total Cost to Health System**|
|---|---|---|
|85,000|500,000 people|RM 42.5 million|
|95,000|1.5 million people|RM 142.5 million|

- **Observation**: Both interventions are **cost-effective** (ICER < RM 120,000), but the second costs **3√ó more** overall due to its larger target population.
- **Implication**: Budget constraints may prioritize the lower-cost intervention, even if its ICER is slightly higher, as the total financial burden is more manageable.

The example underscores a critical distinction: **cost-effectiveness** focuses on the cost per unit of health gain (e.g., per QALY), while **budget impact** considers the **aggregate cost** of rolling out the intervention. The first intervention, with an ICER of RM 85,000, is more cost-effective and requires only RM 42.5 million annually, making it attractive for budget-constrained systems. The second, despite a still-acceptable ICER of RM 95,000, demands RM 142.5 million due to its larger scale, potentially straining resources. This comparison highlights why policymakers must look beyond ICERs to ensure fiscal sustainability, especially in resource-limited settings like Malaysia‚Äôs public health system.

### Why Budget Impact Matters üìã

The distinction between cost-effectiveness and budget impact is crucial for understanding their roles in health policy. The following table compares their key aspects:

|**Aspect**|**Cost-Effectiveness**|**Budget Impact**|
|---|---|---|
|**Focus**|Cost per QALY is low|Total national spend may be too high|
|**Purpose**|Justifies value-for-money|Addresses affordability and fiscal space|
|**Use Case**|Suitable for HTA decisions|Weighed against competing priorities|

- **Fiscal Space**: A government‚Äôs capacity to undertake additional spending or revenue reductions without **kindizing** (jeopardizing) its financial stability. This concept is critical for assessing whether a health system can absorb the costs of a new intervention without compromising other services.
- **Key Question**: Policymakers ask, ‚ÄúCan we afford it for everyone who needs it?‚Äù not just ‚ÄúIs it worth it per patient?‚Äù This shift in perspective ensures that interventions align with the health system‚Äôs overall financial capacity.

**Elaboration**: **Cost-effectiveness**, measured by the ICER, is a cornerstone of **Health Technology Assessments (HTAs)**, helping to identify interventions that deliver the most health benefits per unit of cost. However, a low ICER does not address whether the health system can afford to implement the intervention across the entire target population. **Budget impact** fills this gap by quantifying the total financial commitment, which is critical for planning and prioritization. For example, an intervention with a low ICER may still be rejected if its budget impact exceeds the available **fiscal space**, forcing policymakers to consider trade-offs with other health programs. The term ‚Äúkindizing‚Äù (likely a typo for ‚Äújeopardizing‚Äù in the original text) emphasizes the risk to financial stability, underscoring the importance of aligning interventions with budgetary realities.

### Policy Trade-Offs ‚öñÔ∏è

Implementing a cost-effective intervention requires navigating several trade-offs to ensure it is affordable and feasible at scale. The following table outlines key factors and considerations:

|**Factor**|**Consideration**|
|---|---|
|**Fiscal Space**|Is this within the current Ministry of Health budget? Limited budgets may restrict funding, even for cost-effective interventions.|
|**Opportunity Cost**|What other services would be displaced? Funding one intervention may reduce resources for other critical programs.|
|**Implementation Feasibility**|Is the delivery infrastructure in place? Interventions requiring new systems or training may face delays or increased costs.|

- **Conclusion**: An intervention must be **both cost-effective and affordable** to be implementable at scale. Policymakers must balance the value of health gains with the practical realities of budget constraints and system capacity.

The trade-offs listed highlight the multidimensional nature of health policy decisions. **Fiscal space** is a limiting factor in many health systems, particularly in publicly funded systems like Malaysia‚Äôs, where budgets are fixed and competing priorities abound. **Opportunity cost** forces policymakers to consider what might be sacrificed‚Äîe.g., funding diabetes screening might reduce resources for maternal health programs. **Implementation feasibility** is equally critical; an intervention requiring extensive infrastructure (e.g., new IT systems) may be cost-effective but impractical within a short timeframe. The conclusion that interventions must be **both cost-effective and affordable** emphasizes the need for a pragmatic approach, where economic evaluations inform but do not dictate decisions. Policymakers must integrate budget impact analyses with ICERs to ensure that interventions are sustainable and aligned with public health goals.

---

## 7. Costing in Policy: The Role of DRG/Case-Mix Costing üè•

**Diagnosis-Related Group (DRG)** or **case-mix costing** is a cornerstone of health economics, offering a **standardized method** for classifying patients and estimating healthcare costs. Widely used in policy and economic evaluations, DRG systems facilitate efficient resource allocation and budgeting in healthcare systems. This section explores the definition, mechanics, and applications of DRG/case-mix costing, with a focus on its implementation in Malaysia, its limitations, and its comparison with micro-costing. By understanding DRG‚Äôs role, students can appreciate how it transforms clinical data into **scalable, policy-relevant tools** that bridge patient care and national financing strategies.

### What is DRG/Case-Mix Costing? üìã

- **Definition**: DRGs classify patients into **clinically similar groups** expected to consume **similar healthcare resources**. This system groups patients based on shared characteristics, such as diagnoses or procedures, to streamline cost estimation.
- **Mechanism**: Each DRG group is assigned a **cost weight** based on the average cost of care, which is multiplied by a **base rate** to estimate **reimbursement or cost per admission**. This standardized approach simplifies costing across diverse patient populations.
- **Purpose**: Provides **scalable, standardized cost estimates** for budgeting, reimbursement, and economic evaluations, enabling health systems to manage resources efficiently and support policy decisions.

DRG/case-mix costing is designed to balance clinical accuracy with administrative efficiency. By grouping patients with similar resource needs (e.g., all appendectomy patients), it reduces the complexity of individual cost calculations while maintaining relevance for hospital financing and policy planning. This scalability makes DRG a vital tool for **Universal Health Coverage (UHC)** systems, where standardized costing supports equitable resource distribution across large populations. The **cost weight** reflects the relative resource intensity of each group, while the **base rate** adjusts for local economic conditions, making DRG adaptable to different healthcare systems.

### How DRG-Based Costing Works üõ†Ô∏è

The process of DRG-based costing follows a systematic approach to translate clinical data into financial estimates:

1. **Classify Patient**: Based on **diagnosis, procedures, and comorbidities**, patients are categorized using clinical data from medical records.
2. **Assign DRG Group**: Each patient is assigned to a specific DRG group that reflects their clinical profile and expected resource use.
3. **Determine Cost Weight**: Each DRG group has a **relative cost weight** (e.g., Appendectomy = 0.85, Stroke = 1.7), representing the average resource intensity relative to a baseline procedure.
4. **Calculate Cost**: Multiply the DRG weight by the **national base rate** to calculate the cost per case, providing a standardized cost estimate.
5. **Apply Cost Estimates**: These estimates are used for **reimbursement, budgeting, or economic evaluation (EE) inputs**, informing hospital financing and policy decisions.

This stepwise process ensures that costs are estimated consistently across hospitals and patient groups, facilitating fair reimbursement and efficient budgeting. For example, a stroke patient (DRG weight = 1.7) requires more resources than an appendectomy patient (DRG weight = 0.85), and the cost calculation reflects this difference. By relying on clinical coding, DRG systems link medical practice to financial outcomes, making them indispensable for large-scale health policy applications, such as setting provider payments or evaluating new interventions in **Health Technology Assessments (HTAs)**.

### Base Rate Formula üìä

The **base rate (BR)** is a critical component of DRG costing, determined by the hospital‚Äôs budget and patient volume:

$$\text{BR}_t = \frac{\text{HP}_t}{\text{Cases}_{h,t-1}}$$

- **$\text{BR}_t$**: Base rate in year ( t ), representing the average cost per encounter.
- **$\text{HP}_t$**: Hospital Pool (budget) in year ( t ), reflecting the total financial resources allocated to the hospital.
- **$\text{Cases}_{h,t-1}$**: Total number of patients in hospital ( h ) in year ( t-1 ), used as a denominator to average costs across cases.
- **Interpretation**: The base rate reflects the **average cost per encounter**, adjusted for hospital budget and patient load, ensuring that cost estimates align with the facility‚Äôs financial capacity.

The base rate formula ensures that DRG costs are context-specific, accounting for variations in hospital budgets and patient volumes. For instance, a hospital with a larger budget or fewer patients will have a higher base rate, reflecting higher per-case costs. This formula allows DRG systems to adapt to different healthcare settings, making them versatile for national or regional policy applications. The use of the previous year‚Äôs patient volume ((\text{Cases}_{h,t-1})) ensures stability in cost estimates, as current-year data may be incomplete during budgeting.

### Why DRG Matters for Policy and EE üåç

DRG/case-mix costing is a powerful tool for health policy and economic evaluations, offering several benefits:

|**Use Case**|**Benefit**|
|---|---|
|**Large-Scale Costing in HTAs**|Faster, standardized estimation for many services, enabling efficient evaluation of interventions across populations.|
|**Setting Tariffs and Provider Payments**|Ensures **fair and predictable hospital financing**, aligning payments with resource use.|
|**Comparing Hospitals or Programs**|Benchmarks **efficiency** using case-mix adjusted outputs, allowing comparisons across facilities or health programs.|

DRG‚Äôs ability to provide **standardized, scalable cost estimates** makes it ideal for **HTAs**, where rapid costing of multiple interventions is needed. For provider payments, DRG ensures that hospitals are reimbursed based on the complexity of cases, promoting fairness and transparency. When comparing hospitals, DRG adjusts for differences in patient complexity, enabling policymakers to identify efficient facilities or programs. These applications make DRG a linchpin for **evidence-based policy**, supporting decisions that optimize resource allocation and improve health system performance.

### Malaysia‚Äôs Use of DRG üá≤üáæ

- **Implementation**: The **casemix system** is used in **Ministry of Health (MOH)** and **university hospitals** in Malaysia, integrating DRG into healthcare financing.
- **Tool**: The **UNU-CBG Grouper** generates DRG codes, translating clinical data into standardized groups for costing.
- **Applications**:
    - Supports **internal costing studies** and **MaHTAS (Malaysian Health Technology Assessment Section)** economic evaluations, providing data for policy decisions.
    - **Cost per episode** is preferred over itemized billing for **generalizability**, as it simplifies cost comparisons across diverse settings.
- **Challenges**: Malaysia‚Äôs public healthcare system is not yet fully ready for **DRG-based payments** due to:
    - **Irregular IT infrastructure**, which hinders consistent data collection and coding.
    - **Need for standardized digital health systems and training** to ensure accurate DRG assignment and cost estimation.
    - **Requirement for stakeholder engagement and transparency** in tariff setting to build trust and acceptance among hospital administrators, clinicians, and policymakers.

Malaysia‚Äôs adoption of the casemix system reflects a commitment to modernizing healthcare financing, particularly in **MOH and university hospitals**. The **UNU-CBG Grouper** automates DRG coding, ensuring consistency, but the system‚Äôs effectiveness depends on robust IT infrastructure and trained personnel. The preference for **cost per episode** over itemized billing enhances generalizability, making it easier to compare costs across hospitals or regions. However, challenges like outdated IT systems and the need for stakeholder buy-in highlight the complexity of transitioning to DRG-based payments. These hurdles require significant investment and time‚Äîpotentially up to five years, as noted in related discussions‚Äîemphasizing the need for strategic planning and capacity building.

### Limitations of DRG Costing ‚ö†Ô∏è

- **Less Precise**: Not as accurate as micro-costing, especially for **new interventions** where cost weights may not yet exist.
- **Misses Outliers**: May not capture costs of **non-standardized or outlier care**, such as rare conditions or complex cases.
- **Data Dependency**: Requires **robust clinical coding and data systems** to ensure accurate patient classification and cost estimation.
- **Conclusion**: DRG offers **scalable, standardized inputs** for policy and EE, particularly in **Universal Health Coverage (UHC)** and **hospital payment reform**, but its limitations must be acknowledged.

While DRG‚Äôs standardized approach is a strength, its reliance on averages can obscure patient-specific variations, making it less suitable for novel or highly variable interventions. For instance, a new cancer therapy may not fit existing DRG codes, requiring **micro-costing** for precision. Similarly, **outlier cases** (e.g., patients with multiple comorbidities) may incur costs that exceed DRG estimates, leading to underfunding for hospitals. The dependence on **robust clinical coding** underscores the need for high-quality data systems, which can be a barrier in resource-constrained settings like Malaysia. Despite these limitations, DRG remains a critical tool for **UHC** and payment reform, as it provides a scalable framework for managing costs across large populations.

### DRG vs. Micro-Costing üìä

The following table compares **DRG/case-mix** and **micro-costing**, highlighting their definitions, uses, and trade-offs:

|**Approach**|**DRG/Case-Mix**|**Micro-Costing**|
|---|---|---|
|**Definition**|Classifies patients into groups with similar resource use; cost based on group weight √ó base rate|Itemizes every resource used per patient and assigns actual unit cost|
|**Detail Level**|Medium|Very high (line-item detail)|
|**Common Use**|Hospital claims, provider payments, HTAs|Clinical trials, detailed hospital studies|
|**Strengths**|Fast, scalable, standardized; used in real-world systems|Precise, patient-specific cost; ideal for new interventions|
|**Limitations**|Averaged; may miss variation within group|Labor-intensive, less scalable|

**Elaboration**: **DRG/case-mix costing** excels in scenarios requiring rapid, standardized cost estimates, such as hospital budgeting or national HTAs. Its medium detail level balances accuracy and efficiency, making it practical for real-world systems. **Micro-costing**, by contrast, provides granular, patient-specific data, ideal for research or novel interventions but impractical for large-scale applications due to its time-intensive nature. The trade-off between **scalability** (DRG) and **precision** (micro-costing) is a key consideration in EE, requiring policymakers to choose the appropriate method based on the context and goals of the evaluation.

### When to Use DRG vs. Micro-Costing? ü§î

Choosing between DRG and micro-costing depends on the evaluation‚Äôs scope and objectives:

|**Use DRG When‚Ä¶**|**Use Micro-Costing When‚Ä¶**|
|---|---|
|Doing national or provider-level costing|Evaluating a new intervention in a single hospital|
|Feeding large-scale EE models (e.g., MaHTAS)|Collecting data for trial-based cost-effectiveness|
|Estimating average cost of common procedures|Exploring variation across patients or protocols|

**DRG** is preferred for **national or provider-level costing**, such as setting hospital budgets or informing MaHTAS evaluations, due to its ability to handle large datasets efficiently. It is also ideal for **common procedures** with established cost weights. **Micro-costing**, however, is better suited for **clinical trials** or **new interventions**, where detailed cost data is needed to capture variability. For example, evaluating a new surgical technique in a single hospital might require micro-costing to account for unique resource use, while DRG is more appropriate for routine procedures like appendectomies. Understanding when to use each method ensures that EEs are both accurate and practical.

### Policy Application üåü

- **DRG-Based Costing**: Widely accepted for **HTA submissions** and **provider payment reforms** (e.g., capitation, bundled payment), as it provides standardized, scalable cost estimates.
- **Micro-Costing**: Better suited for **research trials**, **early-phase HTA**, and **new technologies** not yet covered by DRG codes, where precision is critical.
- **Key Insight**: **Micro-costing gives precision; DRG gives scalability**. Good EEs know when to use each or both, depending on the policy context.
- **Role in Policy**: DRG systems turn **clinical data into budgetary tools**, connecting patient care to **national financing strategy**, ensuring that resources are allocated efficiently and equitably.

In policy contexts, **DRG-based costing** supports reforms like **capitation** (fixed payments per patient) or **bundled payments** (single payments for an episode of care), promoting predictability and fairness in hospital financing. **Micro-costing**, while less common in policy, is invaluable for early-stage evaluations of innovative treatments, where DRG codes may not yet exist. The **key insight**‚Äîbalancing precision and scalability‚Äîhighlights the complementary roles of these methods. For instance, a national UHC program might use DRG for routine services but rely on micro-costing for pilot projects. By transforming clinical data into **budgetary tools**, DRG systems align patient care with national priorities, supporting equitable access and efficient resource use in health systems like Malaysia‚Äôs.

---

## 8. Willingness-to-Pay (WTP): Valuing Health Gains üí∞

**Willingness-to-Pay (WTP)** is a critical concept in health economics, reflecting the **maximum amount an individual or society is willing to pay** for a unit of health gain, such as one **Quality-Adjusted Life Year (QALY)**, one **Disability-Adjusted Life Year (DALY)** averted, or one case prevented. WTP serves as a cornerstone for determining cost-effectiveness thresholds and guiding health policy decisions. This section explores the role of WTP in policy, methods for its measurement, factors influencing its estimates, and a practical example of a Discrete Choice Experiment (DCE). By understanding WTP, students can better grasp how societal values shape resource allocation in healthcare, ensuring that policies align with both economic and ethical priorities.

### Why is WTP Useful in Policy? üåç

WTP is a vital tool in health policy, providing a framework to assess the value society places on health outcomes and guiding decisions on resource allocation. The following table outlines its key applications:

|**Application**|**Role of WTP**|
|---|---|
|**HTA & Economic Evaluation**|Benchmarks for ICER comparison, helping determine whether an intervention‚Äôs Incremental Cost-Effectiveness Ratio (ICER) is acceptable.|
|**National Drug Pricing & Coverage**|Justifies price caps or inclusion/exclusion decisions, ensuring that drugs and treatments align with societal affordability.|
|**Benefit Package Design (e.g., UHC)**|Determines what services are worth funding, shaping the scope of Universal Health Coverage (UHC) benefit packages.|

**Elaboration**: WTP is instrumental in **Health Technology Assessments (HTAs)**, where it provides a threshold against which ICERs are compared to assess cost-effectiveness. For example, if a new drug‚Äôs ICER exceeds the WTP threshold, it may be excluded from coverage. In **national drug pricing**, WTP helps set price caps, ensuring affordability while incentivizing innovation. For **UHC benefit package design**, WTP informs which services (e.g., screenings, treatments) should be prioritized to maximize health gains within budget constraints. By reflecting societal preferences, WTP ensures that health policies are both economically sound and socially acceptable, aligning with Malaysia‚Äôs goals for equitable healthcare access.

### How is WTP Measured? üìä

WTP is estimated using two primary methods: **Contingent Valuation (CV)** and **Discrete Choice Experiment (DCE)**. Each method has distinct approaches, steps, strengths, and limitations, as summarized in the following table:

|**Method**|**Contingent Valuation (CV)**|**Discrete Choice Experiment (DCE)**|
|---|---|---|
|**Approach**|Directly asks: ‚ÄúHow much would you pay for [health intervention/outcome]?‚Äù|Presents hypothetical options with different attributes (e.g., effectiveness, cost).|
|**Steps**|1. Describe hypothetical scenario (e.g., vaccine, screening, cure).  <br>2. Ask respondents to state a price (open-ended or bidding format).  <br>3. Calculate mean or median WTP.|1. Identify attributes (e.g., effectiveness, side effects, cost).  <br>2. Construct scenarios with varying combinations.  <br>3. Respondents choose between options.  <br>4. Use statistical models (e.g., conditional logit) to estimate the implicit value of each attribute.  <br>5. Derive WTP per unit (e.g., per QALY).|
|**Strengths**|‚úÖ Simple, direct approach, easy to implement and understand.|‚úÖ Captures trade-offs, reflecting how individuals prioritize attributes like effectiveness over cost.|
|**Limitations**|‚ö†Ô∏è Prone to hypothetical bias or overestimation, as respondents may overstate their willingness to pay in hypothetical scenarios.|‚ö†Ô∏è Requires careful design and analysis, as complex scenarios can confuse respondents or lead to biased results.|

**Elaboration**: **Contingent Valuation (CV)** is straightforward, asking respondents directly how much they would pay for a health outcome, such as a new vaccine. Its simplicity makes it accessible, but **hypothetical bias**‚Äîwhere respondents give inflated answers due to the hypothetical nature of the question‚Äîcan skew results. **Discrete Choice Experiments (DCEs)**, by contrast, present respondents with realistic trade-offs (e.g., choosing between a more effective but costlier treatment), using statistical models to infer WTP. While DCEs better capture preferences, they require **careful design** to avoid overwhelming respondents with complex choices. Both methods contribute to setting WTP thresholds, but their accuracy depends on robust survey design and representative sampling, particularly in diverse populations like Malaysia‚Äôs.

### Factors Influencing WTP Estimates üîç

Several factors influence the accuracy and variability of WTP estimates, reflecting the complexity of capturing societal values:

- **Income and Education Level**: Higher income/education often correlates with higher WTP, as wealthier or more educated individuals may prioritize health investments.
- **Framing of Scenario**: The **severity or urgency** of the health condition affects responses. For example, respondents may be willing to pay more for a life-saving treatment than a preventive measure.
- **Cultural Attitudes**: Attitudes toward **risk and fairness** vary by society, influencing WTP. In some cultures, collective responsibility may lead to higher WTP for public health programs.
- **Public Funding Awareness**: Concerns about **equity and public budgets** influence WTP, as respondents may lower their estimates if they expect government subsidies.
- **Key Insight**: WTP reflects **societal values** for health, but its estimation requires **careful design and interpretation** to account for these influencing factors.

**Elaboration**: These factors highlight the dynamic nature of WTP estimates. For instance, in Malaysia, where income disparities exist, **income and education levels** can significantly affect WTP, potentially skewing thresholds toward wealthier groups if not carefully managed. The **framing of scenarios** is critical; a question about paying for cancer treatment may elicit higher WTP than one about routine screenings due to perceived urgency. **Cultural attitudes** in Malaysia‚Äôs multicultural society may prioritize communal health benefits, influencing WTP for UHC programs. **Public funding awareness** can also temper WTP, as respondents may expect subsidized healthcare, reducing their stated willingness to pay out-of-pocket. These factors necessitate rigorous survey design to ensure WTP reflects true societal preferences, avoiding biases that could misguide policy.

### Simplified DCE Example üé≤

**Scenario**: Choosing between two hypothetical **cancer screening programs** with three attributes:

- **Effectiveness**: % reduction in cancer death.
- **Side Effects**: Temporary nausea.
- **Out-of-Pocket Cost**: RM.

The following table presents the options:

|**Attribute**|**Option A**|**Option B**|
|---|---|---|
|**Effectiveness**|60% reduction in mortality|40% reduction in mortality|
|**Side Effects**|Mild nausea for 1 day|No side effects|
|**Cost**|RM 200|RM 50|

**Question**: Which option would you choose?

**Analysis**: If respondents choose **Option A** despite the higher cost, they value **effectiveness** over cost. Using regression models (e.g., **conditional logit**), we can estimate:

- WTP per 1% reduction in mortality.
- WTP per QALY (with assumptions about utility and life-years).

**Conclusion**: DCEs quantify **trade-offs**, helping infer **real-world WTP values** by analyzing how individuals prioritize attributes like effectiveness, side effects, and cost.

**Elaboration**: This simplified DCE illustrates how individuals make trade-offs in healthcare decisions. If many respondents choose **Option A**, it suggests a higher WTP for a 20% improvement in mortality reduction, despite mild side effects and a higher cost. The use of **conditional logit models** allows analysts to quantify the value placed on each attribute (e.g., RM per 1% mortality reduction), which can be translated into WTP per QALY with assumptions about health utility and life expectancy. In a Malaysian context, such experiments could inform policies like cancer screening programs under UHC, ensuring that public preferences guide resource allocation. The **conclusion** emphasizes DCEs‚Äô ability to capture nuanced trade-offs, making them a powerful tool for setting WTP thresholds that reflect societal values.

---

## 9. Ethical and Equity Implications of WTP ‚öñÔ∏è

Economic evaluations based on **Willingness-to-Pay (WTP)** and **Incremental Cost-Effectiveness Ratios (ICERs)** prioritize **efficiency**, aiming to maximize health gain per ringgit spent. However, real-world health policy decisions often extend beyond efficiency to incorporate **equity** and **ethical considerations**, ensuring that healthcare resources are distributed fairly and align with societal values. This section explores the tension between efficiency and equity, poses critical ethical questions, and examines scenarios where policymakers may deviate from strict ICER-based decisions. By understanding these implications, students can appreciate the moral complexities of health policy and the need to balance economic rigor with fairness and societal priorities.

### The Efficiency vs. Equity Dilemma ü§î

- **Efficiency**: Focuses on **cost-effectiveness** and **resource allocation**, prioritizing interventions that deliver the greatest health benefits for the least cost, as measured by ICERs compared to WTP thresholds.
- **Equity**: Ensures **fair access**, especially for **vulnerable or marginalized groups**, such as low-income populations, rural communities, or those with rare diseases.
- **Challenge**: Balancing efficiency with fairness in **resource-constrained settings**, where prioritizing cost-effective interventions may inadvertently exclude disadvantaged groups or those with high-cost needs.

**Elaboration**: The **efficiency vs. equity dilemma** is a central challenge in health policy. Efficiency-driven evaluations, rooted in WTP and ICERs, aim to optimize health outcomes within budget constraints, often favoring interventions with low ICERs. However, this approach can exacerbate inequities if it overlooks groups with limited access to care or conditions requiring expensive treatments, such as rare diseases. In resource-constrained settings like Malaysia‚Äôs public healthcare system, policymakers must navigate this tension, ensuring that efficiency does not come at the expense of fairness. For example, a highly cost-effective intervention may primarily benefit urban populations, leaving rural communities underserved, thus raising ethical concerns about equitable access.

### Ethical Questions to Consider ‚ùì

To address the broader implications of WTP and ICERs, policymakers must grapple with several ethical questions:

1. **Should rare diseases or end-of-life care have higher WTP thresholds?**
    - These conditions often have high ICERs due to costly treatments or limited patient populations, prompting debate about whether societal values justify higher thresholds.
2. **Do we value a QALY for a child more than an adult?**
    - Children may be prioritized due to their potential for longer life expectancy, raising questions about how to weigh QALYs across age groups.
3. **Is it fair if the rich can ‚Äúafford‚Äù more health than the poor?**
    - WTP estimates may reflect income disparities, potentially favoring interventions accessible to wealthier groups, which challenges the principle of equitable healthcare.

These questions highlight the moral complexities of applying WTP in policy. For **rare diseases** or **end-of-life care**, higher WTP thresholds may be justified by societal values like compassion or the need to address unmet medical needs, even if ICERs are unfavorable. The question about **QALY valuation** for children versus adults touches on societal priorities, as investing in pediatric care may yield long-term benefits but compete with immediate needs of other groups. The issue of **income disparities** is particularly relevant in Malaysia, where socioeconomic inequalities could skew WTP estimates, potentially prioritizing interventions that benefit wealthier populations. These questions require policymakers to integrate ethical reasoning with economic data, ensuring decisions reflect both efficiency and fairness.

### When Policymakers Deviate from ICER Rules üö´

Policymakers may prioritize interventions despite high ICERs due to **ethical or societal values**, recognizing that cost-effectiveness is not the sole determinant of funding decisions. The following table outlines common scenarios and justifications for such deviations:

|**Scenario**|**Common Justification**|
|---|---|
|**End-of-Life Care**|Societal duty to support **dignity**, even if cost is high, reflecting a commitment to compassionate care.|
|**Rare Diseases/Orphan Drugs**|High cost per QALY, but **high unmet need**, as these conditions often lack alternative treatments.|
|**Marginalized Populations**|Priority to **reduce health inequities**, ensuring access for underserved groups like rural or low-income communities.|
|**Childhood Interventions**|**Perceived lifetime benefit** or **moral imperative**, as investing in children may yield long-term societal gains.|

**Example Dilemma**: Two interventions with the same ICER‚Äîone saves lives in **poor rural communities**, the other slightly extends life for the **wealthy**. Which would you fund, and why?  
**Key Insight**: **Cost-effectiveness is essential, but fairness, need, and transparency** also matter in real-world decisions, requiring policymakers to weigh societal values alongside economic metrics.

The table illustrates scenarios where **ethical and societal considerations** override strict adherence to ICERs. For **end-of-life care**, society may value providing comfort and dignity, justifying higher costs despite unfavorable ICERs. **Rare diseases** and **orphan drugs** often have high ICERs due to small patient populations, but their unmet needs drive prioritization, as seen in policies supporting specialized treatments. **Marginalized populations** are prioritized to address health disparities, a key concern in Malaysia‚Äôs diverse society. **Childhood interventions** are often favored due to their long-term benefits, reflecting a moral commitment to future generations. The **example dilemma** challenges students to articulate their rationale, considering whether equity (favoring rural communities) or efficiency (maximizing health gains) should take precedence. This underscores the **key insight** that cost-effectiveness must be balanced with fairness, need, and transparency, ensuring that policies reflect societal values and promote equitable healthcare access.

---

## 10. Bringing It All Together: Decision Frameworks üß†

Economic evaluation is a **tool, not the whole answer**, providing critical evidence but requiring integration with broader considerations to inform health policy decisions. While tools like **Incremental Cost-Effectiveness Ratios (ICERs)** and **Willingness-to-Pay (WTP)** thresholds offer quantitative insights, real-world policy-making demands a holistic approach that accounts for ethical, practical, and societal factors. **Multi-Criteria Decision Analysis (MCDA)** is a structured framework that combines evidence with values and constraints, enabling policymakers to make informed, balanced decisions. This section explores MCDA‚Äôs role in health policy, illustrating how it synthesizes diverse criteria through a practical example, equipping students to navigate the complexities of policy-making with rigor and nuance.

### Multi-Criteria Decision Analysis (MCDA) üìä

**Multi-Criteria Decision Analysis (MCDA)** combines evidence with values and constraints, **scoring and weighting criteria** to inform decisions. It provides a systematic approach to evaluate interventions by considering multiple dimensions beyond cost-effectiveness, ensuring that policies reflect both economic and societal priorities. The following table outlines key criteria and their associated considerations:

|**Criterion**|**Example Considerations**|
|---|---|
|**Cost-Effectiveness**|ICER vs. WTP threshold: Does the intervention‚Äôs ICER fall below the acceptable cost per QALY or DALY averted?|
|**Budget Impact**|Can the system afford this intervention? What is the total financial burden when scaled to the target population?|
|**Equity**|Will it reduce disparities? Reach marginalized groups, such as rural communities or low-income populations?|
|**Severity of Disease**|Is it life-threatening or high burden? Does the intervention address critical public health needs?|
|**Feasibility of Delivery**|Infrastructure, training, supply chain: Are the necessary resources and systems in place for implementation?|
|**Public/Political Support**|Acceptability and urgency for implementation: Is there stakeholder buy-in or public demand for the intervention?|

MCDA is a powerful tool for navigating the "messy, complex world of policy" by integrating diverse factors into a cohesive decision-making framework. **Cost-effectiveness**, measured by comparing ICERs to WTP thresholds, ensures economic efficiency, but **budget impact** assesses affordability at scale, preventing fiscal overstretch. **Equity** prioritizes fairness, ensuring that interventions benefit underserved groups, a key concern in Malaysia‚Äôs diverse society. **Severity of disease** weighs the urgency of health needs, while **feasibility of delivery** addresses practical constraints like infrastructure or workforce capacity. **Public/political support** ensures that interventions are viable in the eyes of stakeholders and the public, enhancing their likelihood of successful implementation. By scoring and weighting these criteria, MCDA provides a transparent, evidence-based approach to prioritize interventions, balancing quantitative data with qualitative values.

### Simplified MCDA Scoring Table üìä

To illustrate MCDA in practice, the following table evaluates three interventions‚Äî**HPV Self-Sampling**, **Stroke Rehab**, and **Diabetes Screen**‚Äîbased on the criteria above, using a simplified scoring system:

|**Intervention**|**ICER**|**Budget Impact**|**Equity Benefit**|**Feasibility**|**Total Score**|
|---|---|---|---|---|---|
|**HPV Self-Sampling**|‚úÖ Strong|‚ö†Ô∏è Moderate|‚úÖ Strong|‚úÖ Strong|High|
|**Stroke Rehab**|‚ö†Ô∏è Moderate|‚úÖ Strong|‚ö†Ô∏è Moderate|‚ö†Ô∏è Moderate|Moderate|
|**Diabetes Screen**|‚úÖ Strong|‚ùå Weak|‚úÖ Strong|‚ö†Ô∏è Moderate|Moderate|

- **Legend**: ‚úÖ = Strong, ‚ö†Ô∏è = Moderate, ‚ùå = Weak.
- **Conclusion**: **Good policy needs evidence, ethics, and economics**. MCDA helps combine these elements systematically, ensuring that decisions are transparent, balanced, and aligned with societal goals.

The scoring table demonstrates how MCDA synthesizes multiple criteria to guide policy decisions. **HPV Self-Sampling** scores highly due to its favorable ICER, strong equity benefits (targeting women‚Äôs health), and feasible implementation, despite a moderate budget impact. **Stroke Rehab** benefits from a low budget impact but is hindered by a less favorable ICER and moderate equity and feasibility scores, resulting in a moderate overall score. **Diabetes Screen** has a strong ICER and equity benefit but is constrained by a high budget impact, leading to a moderate score. The **legend** clarifies the scoring system, where ‚úÖ indicates a strong performance, ‚ö†Ô∏è suggests moderate challenges, and ‚ùå highlights significant weaknesses. The **conclusion** emphasizes that **good policy** integrates **evidence** (e.g., ICERs), **ethics** (e.g., equity), and **economics** (e.g., budget impact), with MCDA providing a structured method to weigh these factors. In Malaysia‚Äôs context, MCDA could guide decisions on UHC benefit packages, ensuring that interventions like HPV screening are prioritized for their broad societal impact.

---

## 11. What Makes an Economic Evaluation Policy-Relevant? üìú

A **policy-relevant economic evaluation (EE)** is designed to **inform real-world decisions**, not merely contribute to academic publications. To achieve this, it must be **timely**, **context-specific**, and **actionable**, addressing the practical needs of policymakers while aligning with the realities of the health system. This section outlines the key features that distinguish policy-relevant EEs and contrasts them with academic EEs, emphasizing how they bridge the gap between theoretical analysis and practical impact. By understanding these characteristics, students can craft EEs that drive meaningful policy changes, ensuring that health resources are allocated efficiently and equitably in settings like Malaysia‚Äôs public healthcare system.

### Key Features of Policy-Relevant EEs üåü

A **policy-relevant EE** goes beyond technical accuracy to provide actionable insights that resonate with decision-makers. The following table details the essential features and their practical manifestations:

|**Feature**|**What It Looks Like**|
|---|---|
|**Timely**|Aligned with current policy windows or funding cycles, ensuring that the EE addresses immediate priorities or opportunities for action.|
|**Context-Specific**|Uses **local data**, pricing, epidemiology, and delivery platforms, reflecting the specific health system and population characteristics of the region (e.g., Malaysia).|
|**Feasible Comparator**|Includes the **actual standard of care**, not just placebo or ‚Äúdo nothing,‚Äù to ensure relevance to real-world practice.|
|**Scalable Cost Estimates**|Costing methods align with **national budgeting tools** (e.g., Diagnosis-Related Group (DRG), Universal Coverage Budget (UCB)), enabling integration into existing financial frameworks.|
|**Considers Affordability**|Includes **budget impact analysis** alongside ICER, assessing whether the intervention is financially sustainable at scale.|
|**Explores Equity Implications**|Shows how different groups are affected or protected, addressing disparities for marginalized or underserved populations.|
|**Presented Accessibly**|Uses **clear tables, visuals, ICER interpretation**, and stakeholder-friendly language to communicate findings effectively to non-technical audiences.|
|**Linked to Decision Criteria**|Tied to **threshold values**, priority-setting goals, and policy mandates, ensuring alignment with broader health system objectives.|

These features ensure that EEs are not only rigorous but also **relevant** to policy contexts. **Timeliness** ensures that findings align with current funding cycles or policy debates, such as Malaysia‚Äôs efforts to expand Universal Health Coverage (UHC). **Context-specificity** grounds the EE in local realities, using Malaysian epidemiology or pricing data to reflect the population‚Äôs needs. A **feasible comparator** ensures that the evaluation compares new interventions to existing practices, not theoretical baselines. **Scalable cost estimates**, such as those using DRG, align with national budgeting systems, facilitating implementation. **Affordability** and **equity** considerations ensure that interventions are sustainable and fair, while **accessible presentation** makes complex data understandable to policymakers. Finally, linking to **decision criteria** ensures that the EE addresses specific policy goals, such as reducing health disparities or meeting WTP thresholds, making it a practical tool for action.

### Academic EE vs. Policy-Relevant EE üìö

The distinction between academic and policy-relevant EEs lies in their purpose and approach. The following table compares these two types:

|**Aspect**|**Academic EE**|**Policy-Relevant EE**|
|---|---|---|
|**Utility Scores**|Uses **generic utility scores**, often from international datasets, which may not reflect local preferences.|Uses **Malaysian EQ-5D tariffs** or **local preferences**, ensuring cultural and contextual relevance.|
|**Budget Impact**|Often **omitted**, focusing solely on cost-effectiveness metrics like ICER.|Includes **fiscal sustainability estimates**, assessing the total financial burden of implementation.|
|**Focus**|Emphasizes **methodological novelty**, aiming to advance academic knowledge or develop new techniques.|Answers an **urgent policy question**, addressing immediate needs or priorities in the health system.|

**Academic EEs** prioritize rigor and innovation, often using standardized utility scores (e.g., global QALY metrics) that may not capture Malaysia‚Äôs unique health preferences. They may neglect budget impact, focusing on theoretical cost-effectiveness. In contrast, **policy-relevant EEs** are grounded in local realities, using tools like the **Malaysian EQ-5D tariffs** to reflect societal values. They incorporate **budget impact** to ensure affordability, addressing questions like, ‚ÄúCan Malaysia‚Äôs Ministry of Health fund this intervention?‚Äù Their focus on **urgent policy questions** ensures immediate relevance, such as evaluating new UHC services or addressing public health crises. This distinction highlights the need for EEs to be tailored to decision-makers‚Äô needs, moving beyond academic exercises to drive tangible outcomes.

**Key Takeaway**: A good economic evaluation **informs decisions, not just publications**. By being timely, context-specific, and actionable, policy-relevant EEs shape resource allocation, improve access, and promote equity in health systems.

The **key takeaway** underscores the transformative potential of policy-relevant EEs. Unlike academic EEs, which may remain theoretical, policy-relevant EEs directly influence **who gets access**, **what gets funded**, and **how systems evolve**. For example, an EE that uses local data and clear visuals to demonstrate the affordability and equity benefits of a new screening program can persuade policymakers to prioritize it in Malaysia‚Äôs UHC framework. By aligning with decision criteria and presenting findings accessibly, these EEs ensure that evidence translates into action, ultimately improving health outcomes and system efficiency.

---

## 12. Summary: What We‚Äôve Learned Across Four Lectures üìñ

The **Economic Evaluation series** (EE I‚ÄìIV) in the Health Economics module (MQB7014) provides a **comprehensive framework** for understanding, conducting, appraising, and applying economic evaluations in health policy. This series equips students with the knowledge and skills to navigate the complexities of health economics, from foundational concepts to practical policy applications. Each lecture builds on the previous one, creating a cohesive learning journey that prepares students to make evidence-based, ethical, and impactful decisions in healthcare systems like Malaysia‚Äôs. This section summarizes the key learnings from each lecture, highlighting their core components and their relevance to real-world health policy challenges.

### EE I: Foundations of Economic Evaluation üèõÔ∏è

- **Understand Types**:
    - **Cost-Effectiveness Analysis (CEA)**: Compares costs and health outcomes (e.g., lives saved) to assess value for money.
    - **Cost-Utility Analysis (CUA)**: Measures outcomes in Quality-Adjusted Life Years (QALYs) or Disability-Adjusted Life Years (DALYs) to account for quality of life.
    - **Cost-Benefit Analysis (CBA)**: Converts health outcomes into monetary values for broader comparisons.
- **Key Steps**:
    - **Define perspective**: Choose the viewpoint (e.g., healthcare system, societal) to determine relevant costs and outcomes.
    - **Identify costs/outcomes**: Quantify all relevant expenses and health effects.
    - **Analyze results**: Calculate metrics like Incremental Cost-Effectiveness Ratios (ICERs) to inform decisions.

**EE I** lays the groundwork by introducing the **types of economic evaluations**‚ÄîCEA, CUA, and CBA‚Äîeach suited to different policy questions. CEA is ideal for comparing interventions with similar outcomes, CUA incorporates quality of life for broader applicability, and CBA allows comparisons across sectors. The **key steps** provide a structured approach to conducting evaluations, ensuring that analyses are systematic and relevant. For example, in Malaysia, choosing a **healthcare system perspective** might focus on Ministry of Health costs, while a **societal perspective** includes patient travel expenses. This foundational knowledge is critical for designing robust evaluations that inform policy decisions.

### EE II: Methodological Essentials üõ†Ô∏è

- **Costing**:
    - Use **micro-costing** for detailed, patient-specific cost estimates, ideal for clinical trials.
    - Use **DRG/case-mix methods** for standardized, scalable costing in hospital and national settings.
- **Outcomes**:
    - Measure in **QALYs/DALYs** to capture health benefits in terms of quality and quantity of life.
    - Apply **discounting** to account for the time value of costs and benefits.
- **Modeling**:
    - Use **decision trees** for short-term interventions with discrete outcomes.
    - Use **Markov models** for chronic conditions with ongoing states and transitions.

**EE II** dives into the technical aspects of conducting economic evaluations, providing tools to quantify costs and outcomes accurately. **Micro-costing** offers precision for novel interventions, while **DRG/case-mix methods** support large-scale policy applications, such as Malaysia‚Äôs casemix system. **QALYs and DALYs** standardize outcome measurement, enabling comparisons across interventions, while **discounting** ensures that future costs and benefits are appropriately valued. **Decision trees** and **Markov models** allow analysts to simulate intervention impacts, crucial for evaluating complex health programs like chronic disease management. These methodologies ensure that evaluations are both rigorous and adaptable to diverse policy contexts.

### EE III: Appraising EE Studies (CHEERS 2022) üìã

- **Apply CHEERS Checklist**: Evaluate **quality and transparency** of economic evaluation studies using the Consolidated Health Economic Evaluation Reporting Standards (CHEERS) 2022 guidelines.
- **Identify Gaps**:
    - **Missing perspective**: Failure to specify whether the analysis is from a healthcare or societal viewpoint.
    - **Weak sensitivity analysis**: Inadequate testing of assumptions or uncertainty in results.
    - **Unjustified time horizon**: Choosing an inappropriate duration for the analysis, affecting validity.

**EE III** focuses on **critical appraisal**, teaching students to assess the quality of published economic evaluations. The **CHEERS 2022 checklist** provides a standardized framework to ensure studies are transparent and reliable, covering aspects like methodology, data sources, and reporting clarity. Identifying gaps, such as a **missing perspective**, ensures that evaluations align with policy needs (e.g., Malaysia‚Äôs Ministry of Health priorities). **Weak sensitivity analysis** can undermine confidence in results, while an **unjustified time horizon** may misrepresent long-term impacts, such as in chronic disease interventions. This lecture equips students to scrutinize studies critically, ensuring that only robust evidence informs policy decisions.

### EE IV: Interpreting & Applying EE in Policy üåç

- **Interpret ICERs**:
    - Compare ICERs against **WTP thresholds** to assess cost-effectiveness.
    - Consider **budget impact** to evaluate affordability at scale.
- **Understand Equity and Ethics**:
    - Consider **fairness** in resource allocation, prioritizing vulnerable or marginalized groups.
    - Account for **societal values**, such as dignity in end-of-life care or addressing unmet needs.
- **Use Tools like MCDA**:
    - Employ **Multi-Criteria Decision Analysis (MCDA)** to combine evidence with values and constraints, weighing factors like cost-effectiveness, equity, and feasibility.

**EE IV** shifts from technical skills to **practical application**, emphasizing how to use economic evaluations in real-world policy contexts. **Interpreting ICERs** involves not only comparing them to WTP thresholds but also assessing whether the intervention is affordable within budget constraints, a critical consideration in Malaysia‚Äôs resource-limited health system. **Equity and ethics** ensure that policies address disparities, such as access for rural communities, and reflect societal priorities, like supporting rare disease treatments. **MCDA** provides a structured framework to balance these factors, enabling transparent and holistic decision-making. This lecture prepares students to translate evidence into actionable policies that enhance health system efficiency and fairness.

---

## 13. Key Takeaways for Future Health Leaders üåü

As **future health leaders**, your role extends beyond analyzing data to **informing action** that shapes healthcare systems and improves lives. These takeaways empower students to move beyond theoretical analysis, ensuring that their work influences **access, funding, and system evolution** in contexts like Malaysia‚Äôs public healthcare system.

### Critical Lessons for Health Policy Leadership üìã


1. **ICER ‚â† Final Answer**: **Context, budget, equity, and feasibility** are equally important.
    
    - The **Incremental Cost-Effectiveness Ratio (ICER)** is a vital metric for assessing cost-effectiveness, but it is not the sole determinant of policy decisions.
    - Policymakers must consider **context** (e.g., local epidemiology), **budget constraints**, **equity** (e.g., benefits for marginalized groups), and **feasibility** (e.g., infrastructure readiness) to ensure decisions are practical and fair.
    - **Elaboration**: While ICERs provide a quantitative basis for comparing interventions, their interpretation requires a holistic view. For example, an intervention with a low ICER may be unaffordable if its budget impact exceeds fiscal capacity, as seen in Malaysia‚Äôs resource-constrained health system. Similarly, prioritizing equity might justify funding a higher-ICER intervention that serves rural communities, ensuring fairness over pure efficiency.
2. **DRG/Case-Mix Costing**: A **scalable, policy-relevant approach** for national financing and Health Technology Assessments (HTAs).
    
    - **Diagnosis-Related Group (DRG)/case-mix costing** standardizes cost estimates by classifying patients into groups with similar resource use, facilitating budgeting and reimbursement.
    - It supports **national financing strategies** and HTAs, such as Malaysia‚Äôs MaHTAS evaluations, by providing scalable cost data.
    - **Elaboration**: DRG‚Äôs scalability makes it ideal for large-scale policy applications, such as setting hospital tariffs or evaluating UHC programs. In Malaysia, the use of the UNU-CBG Grouper for DRG coding enhances cost generalizability, but challenges like outdated IT systems highlight the need for infrastructure investment. This approach ensures that clinical data informs national financing, aligning patient care with policy goals.
3. **WTP**: Can be derived from **public preferences**, not just GDP-based thresholds.
    
    - **Willingness-to-Pay (WTP)** thresholds can be informed by methods like Contingent Valuation (CV) or Discrete Choice Experiments (DCE), capturing societal values rather than relying solely on economic metrics like 1‚Äì3√ó GDP per capita.
    - **Elaboration**: Public preference-based WTP thresholds, derived from surveys, reflect societal priorities, such as valuing life-saving treatments over preventive measures. In Malaysia, incorporating local preferences (e.g., via Malaysian EQ-5D tariffs) ensures that thresholds align with cultural and economic contexts, making policies more relevant and acceptable to the population.
4. **Policy-Relevant EEs**: Must address **real decisions and real people**, using local data and clear communication.
    
    - Effective EEs are **timely**, **context-specific**, and **actionable**, using local data (e.g., Malaysian pricing, epidemiology) and presenting findings in stakeholder-friendly formats.
    - **Elaboration**: Policy-relevant EEs go beyond academic rigor to address urgent questions, such as which interventions to include in Malaysia‚Äôs UHC benefit package. By using local data and clear visuals, they ensure that policymakers, clinicians, and the public understand the implications, fostering trust and facilitating implementation. This approach ensures that EEs directly influence real-world decisions, impacting patient access and system priorities.
5. **Impact of EEs**: The best economic evaluations **shape access, funding, and system evolution**, not just sit in reports.
    
    - EEs should drive tangible outcomes, influencing **who gets access** to care, **what gets funded**, and **how health systems evolve** to meet population needs.
    - **Elaboration**: The ultimate goal of EEs is to transform health systems by informing resource allocation and policy design. For example, a well-crafted EE might justify funding for a new cancer screening program in Malaysia, improving access for underserved women and reshaping public health priorities. By focusing on actionable outcomes, EEs become catalysts for systemic change, ensuring that health systems are equitable, efficient, and responsive to societal needs.

**Reflection on Broader Impact**: These takeaways collectively empower future health leaders to bridge the gap between analysis and action. By recognizing that **ICERs are not the final answer**, students learn to integrate economic evidence with practical and ethical considerations, ensuring that policies are feasible and fair. **DRG/case-mix costing** and **WTP** provide tools to align evaluations with national priorities, while **policy-relevant EEs** ensure that findings are actionable in local contexts. The emphasis on **impact** underscores the role of health leaders in driving systemic change, making healthcare more accessible and sustainable. In Malaysia, where resource constraints and diverse population needs pose challenges, these lessons are critical for shaping a health system that balances efficiency with equity.

---

